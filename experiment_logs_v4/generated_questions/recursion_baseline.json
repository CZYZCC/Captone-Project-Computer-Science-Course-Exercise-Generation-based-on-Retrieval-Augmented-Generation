{
  "context": [
    {
      "node_id": "tb1_node5",
      "content": "Similar apportionment algorithms are used in multi-party parliamentary elections around the world, where the number of seats allocated to each party is supposed to be proportional to the number of votes that party receives. The two most common are the $D$ ’Hondt method14 and the Webster–Sainte-Laguë method,15 which respectively use priorities $P / ( r + 1 )$ and $P / ( 2 r + 1 )$ in place of the square-root expression in Huntington-Hill. The Huntington-Hill method is essentially unique to the United States House of Representatives, thanks in part to the constitutional requirement that each state must be allocated at least one representative. \n0.4 A Bad Example \nAs a prototypical example of a sequence of instructions that is not actually an algorithm, consider \"Martin’s algorithm”:16 \nBeAMillionaireAndNeverPayTaxes(): Get a million dollars. If the tax man comes to your door and says, “You have never paid taxes!” Say “I forgot.” \nPretty simple, except for that first step; it’s a doozy! A group of billionaire CEOs, Silicon Valley venture capitalists, or New York City real-estate hustlers might consider this an algorithm, because for them the first step is both unambiguous and trivial,17 but for the rest of us poor slobs, Martin’s procedure is too vague to be considered an actual algorithm. On the other hand, this is a perfect example of a reduction—it reduces the problem of being a millionaire and never paying taxes to the “easier” problem of acquiring a million dollars. We’ll see reductions over and over again in this book. As hundreds of businessmen and politicians have demonstrated, if you know how to solve the easier problem, a reduction tells you how to solve the harder one. \nMartin’s algorithm, like some of our previous examples, is not the kind of algorithm that computer scientists are used to thinking about, because it is phrased in terms of operations that are difficult for computers to perform. This book focuses (almost!) exclusively on algorithms that can be reasonably implemented on a standard digital computer. Each step in these algorithms is either directly supported by common programming languages (such as arithmetic, assignments, loops, or recursion) or something that you’ve already learned how to do (like sorting, binary search, tree traversal, or singing $^ { * } n$ Bottles of Beer on the Wall”). \n0.5 Describing Algorithms \nThe skills required to effectively design and analyze algorithms are entangled with the skills required to effectively describe algorithms. At least in my classes, a complete description of any algorithm has four components: \n• What: A precise specification of the problem that the algorithm solves.   \n• How: A precise description of the algorithm itself.   \n• Why: A proof that the algorithm solves the problem it is supposed to solve.   \n• How fast: An analysis of the running time of the algorithm. \nIt is not necessary (or even advisable) to develop these four components in this particular order. Problem specifications, algorithm descriptions, correctness proofs, and time analyses usually evolve simultaneously, with the development of each component informing the development of the others. For example, we may need to tweak the problem description to support a faster algorithm, or modify the algorithm to handle a tricky case in the proof of correctness. Nevertheless, presenting these components separately is usually clearest for the reader. \nAs with any writing, it’s important to aim your descriptions at the right audience; I recommend writing for a competent but skeptical programmer who is not as clever as you are. Think of yourself six months ago. As you develop any new algorithm, you will naturally build up lots of intuition about the problem and about how your algorithm solves it, and your informal reasoning will be guided by that intuition. But anyone reading your algorithm later, or the code you derive from it, won’t share your intuition or experience. Neither will your compiler. Neither will you six months from now. All they will have is your written description. \nEven if you never have to explain your algorithms to anyone else, it’s still important to develop them with an audience in mind. Trying to communicate clearly forces you to think more clearly. In particular, writing for a novice audience, who will interpret your words exactly as written, forces you to work through fine details, no matter how “obvious” or “intuitive” your high-level ideas may seem at the moment. Similarly, writing for a skeptical audience forces you to develop robust arguments for correctness and efficiency, instead of trusting your intuition or your intelligence.18",
      "metadata": {
        "content": "Similar apportionment algorithms are used in multi-party parliamentary elections around the world, where the number of seats allocated to each party is supposed to be proportional to the number of votes that party receives. The two most common are the $D$ ’Hondt method14 and the Webster–Sainte-Laguë method,15 which respectively use priorities $P / ( r + 1 )$ and $P / ( 2 r + 1 )$ in place of the square-root expression in Huntington-Hill. The Huntington-Hill method is essentially unique to the United States House of Representatives, thanks in part to the constitutional requirement that each state must be allocated at least one representative. \n0.4 A Bad Example \nAs a prototypical example of a sequence of instructions that is not actually an algorithm, consider \"Martin’s algorithm”:16 \nBeAMillionaireAndNeverPayTaxes(): Get a million dollars. If the tax man comes to your door and says, “You have never paid taxes!” Say “I forgot.” \nPretty simple, except for that first step; it’s a doozy! A group of billionaire CEOs, Silicon Valley venture capitalists, or New York City real-estate hustlers might consider this an algorithm, because for them the first step is both unambiguous and trivial,17 but for the rest of us poor slobs, Martin’s procedure is too vague to be considered an actual algorithm. On the other hand, this is a perfect example of a reduction—it reduces the problem of being a millionaire and never paying taxes to the “easier” problem of acquiring a million dollars. We’ll see reductions over and over again in this book. As hundreds of businessmen and politicians have demonstrated, if you know how to solve the easier problem, a reduction tells you how to solve the harder one. \nMartin’s algorithm, like some of our previous examples, is not the kind of algorithm that computer scientists are used to thinking about, because it is phrased in terms of operations that are difficult for computers to perform. This book focuses (almost!) exclusively on algorithms that can be reasonably implemented on a standard digital computer. Each step in these algorithms is either directly supported by common programming languages (such as arithmetic, assignments, loops, or recursion) or something that you’ve already learned how to do (like sorting, binary search, tree traversal, or singing $^ { * } n$ Bottles of Beer on the Wall”). \n0.5 Describing Algorithms \nThe skills required to effectively design and analyze algorithms are entangled with the skills required to effectively describe algorithms. At least in my classes, a complete description of any algorithm has four components: \n• What: A precise specification of the problem that the algorithm solves.   \n• How: A precise description of the algorithm itself.   \n• Why: A proof that the algorithm solves the problem it is supposed to solve.   \n• How fast: An analysis of the running time of the algorithm. \nIt is not necessary (or even advisable) to develop these four components in this particular order. Problem specifications, algorithm descriptions, correctness proofs, and time analyses usually evolve simultaneously, with the development of each component informing the development of the others. For example, we may need to tweak the problem description to support a faster algorithm, or modify the algorithm to handle a tricky case in the proof of correctness. Nevertheless, presenting these components separately is usually clearest for the reader. \nAs with any writing, it’s important to aim your descriptions at the right audience; I recommend writing for a competent but skeptical programmer who is not as clever as you are. Think of yourself six months ago. As you develop any new algorithm, you will naturally build up lots of intuition about the problem and about how your algorithm solves it, and your informal reasoning will be guided by that intuition. But anyone reading your algorithm later, or the code you derive from it, won’t share your intuition or experience. Neither will your compiler. Neither will you six months from now. All they will have is your written description. \nEven if you never have to explain your algorithms to anyone else, it’s still important to develop them with an audience in mind. Trying to communicate clearly forces you to think more clearly. In particular, writing for a novice audience, who will interpret your words exactly as written, forces you to work through fine details, no matter how “obvious” or “intuitive” your high-level ideas may seem at the moment. Similarly, writing for a skeptical audience forces you to develop robust arguments for correctness and efficiency, instead of trusting your intuition or your intelligence.18",
        "chapter": "Introduction",
        "section": "A Bad Example",
        "subsection": "N/A",
        "subsubsection": "N/A",
        "textbook_id": 1,
        "node_index": 5
      }
    },
    {
      "node_id": "tb1_node6",
      "content": "I cannot emphasize this point enough: Your primary job as an algorithm designer is teaching other people how and why your algorithms work. If you can’t communicate your ideas to other human beings, they may as well not exist. Producing correct and efficient executable code is an important but secondary goal. Convincing yourself, your professors, your (prospective) employers, your colleagues, or your students that you are smart is at best a distant third. \nSpecifying the Problem \nBefore we can even start developing a new algorithm, we have to agree on what problem our algorithm is supposed to solve. Similarly, before we can even start describing an algorithm, we have to describe the problem that the algorithm is supposed to solve. \nAlgorithmic problems are often presented using standard English, in terms of real-world objects. It’s up to us, the algorithm designers, to restate these problems in terms of formal, abstract, mathematical objects—numbers, arrays, lists, graphs, trees, and so on—that we can reason about formally. We must also determine if the problem statement carries any hidden assumptions, and state those assumptions explicitly. (For example, in the song $^ { * } n$ Bottles of Beer on the Wall”, $n$ is always a non-negative integer.19) \nWe may need to refine our specification as we develop the algorithm. For example, our algorithm may require a particular input representation, or produce a particular output representation, that was left unspecified in the original informal problem description. Or our algorithm might actually solve a more general problem than we were originally asked to solve. (This is a common feature of recursive algorithms.) \nThe specification should include just enough detail that someone else could use our algorithm as a black box, without knowing how or why the algorithm actually works. In particular, we must describe the type and meaning of each input parameter, and exactly how the eventual output depends on the input parameters. On the other hand, our specification should deliberately hide any details that are not necessary to use the algorithm as a black box. Let that which does not matter truly slide. \nFor example, the lattice and duplation-and-mediation algorithms both solve the same problem: Given two non-negative integers $x$ and $y$ , each represented as an array of digits, compute the product $x cdot y$ , also represented as an array of digits. To someone using these algorithms, the choice of algorithm is completely irrelevant. On the other hand, the Greek straightedge-and-compass algorithm solves a different problem, because the input and output values are represented by line segments instead of arrays of digits. \nDescribing the Algorithm \nComputer programs are concrete representations of algorithms, but algorithms are not programs. Rather, algorithms are abstract mechanical procedures that can be implemented in any programming language that supports the underlying primitive operations. The idiosyncratic syntactic details of your favorite programming language are utterly irrelevant; focusing on these will only distract you (and your readers) from what’s really going on.20 A good algorithm description is closer to what we should write in the comments of a real program than the code itself. Code is a poor medium for storytelling. \nOn the other hand, a plain English prose description is usually not a good idea either. Algorithms have lots of idiomatic structure—especially conditionals, loops, function calls, and recursion—that are far too easily hidden by unstructured prose. Colloquial English is full of ambiguities and shades of meaning, but algorithms must be described as unambiguously as possible. Prose is a poor medium for precision. \nIn my opinion, the clearest way to present an algorithm is using a combination of pseudocode and structured English. Pseudocode uses the structure of formal programming languages and mathematics to break algorithms into primitive steps; the primitive steps themselves can be written using mathematical notation, pure English, or an appropriate mixture of the two, whatever is clearest. Wellwritten pseudocode reveals the internal structure of the algorithm but hides irrelevant implementation details, making the algorithm easier to understand, analyze, debug, and implement.",
      "metadata": {
        "content": "I cannot emphasize this point enough: Your primary job as an algorithm designer is teaching other people how and why your algorithms work. If you can’t communicate your ideas to other human beings, they may as well not exist. Producing correct and efficient executable code is an important but secondary goal. Convincing yourself, your professors, your (prospective) employers, your colleagues, or your students that you are smart is at best a distant third. \nSpecifying the Problem \nBefore we can even start developing a new algorithm, we have to agree on what problem our algorithm is supposed to solve. Similarly, before we can even start describing an algorithm, we have to describe the problem that the algorithm is supposed to solve. \nAlgorithmic problems are often presented using standard English, in terms of real-world objects. It’s up to us, the algorithm designers, to restate these problems in terms of formal, abstract, mathematical objects—numbers, arrays, lists, graphs, trees, and so on—that we can reason about formally. We must also determine if the problem statement carries any hidden assumptions, and state those assumptions explicitly. (For example, in the song $^ { * } n$ Bottles of Beer on the Wall”, $n$ is always a non-negative integer.19) \nWe may need to refine our specification as we develop the algorithm. For example, our algorithm may require a particular input representation, or produce a particular output representation, that was left unspecified in the original informal problem description. Or our algorithm might actually solve a more general problem than we were originally asked to solve. (This is a common feature of recursive algorithms.) \nThe specification should include just enough detail that someone else could use our algorithm as a black box, without knowing how or why the algorithm actually works. In particular, we must describe the type and meaning of each input parameter, and exactly how the eventual output depends on the input parameters. On the other hand, our specification should deliberately hide any details that are not necessary to use the algorithm as a black box. Let that which does not matter truly slide. \nFor example, the lattice and duplation-and-mediation algorithms both solve the same problem: Given two non-negative integers $x$ and $y$ , each represented as an array of digits, compute the product $x cdot y$ , also represented as an array of digits. To someone using these algorithms, the choice of algorithm is completely irrelevant. On the other hand, the Greek straightedge-and-compass algorithm solves a different problem, because the input and output values are represented by line segments instead of arrays of digits. \nDescribing the Algorithm \nComputer programs are concrete representations of algorithms, but algorithms are not programs. Rather, algorithms are abstract mechanical procedures that can be implemented in any programming language that supports the underlying primitive operations. The idiosyncratic syntactic details of your favorite programming language are utterly irrelevant; focusing on these will only distract you (and your readers) from what’s really going on.20 A good algorithm description is closer to what we should write in the comments of a real program than the code itself. Code is a poor medium for storytelling. \nOn the other hand, a plain English prose description is usually not a good idea either. Algorithms have lots of idiomatic structure—especially conditionals, loops, function calls, and recursion—that are far too easily hidden by unstructured prose. Colloquial English is full of ambiguities and shades of meaning, but algorithms must be described as unambiguously as possible. Prose is a poor medium for precision. \nIn my opinion, the clearest way to present an algorithm is using a combination of pseudocode and structured English. Pseudocode uses the structure of formal programming languages and mathematics to break algorithms into primitive steps; the primitive steps themselves can be written using mathematical notation, pure English, or an appropriate mixture of the two, whatever is clearest. Wellwritten pseudocode reveals the internal structure of the algorithm but hides irrelevant implementation details, making the algorithm easier to understand, analyze, debug, and implement.",
        "chapter": "Introduction",
        "section": "Describing Algorithms",
        "subsection": "Specifying the Problem",
        "subsubsection": "N/A",
        "textbook_id": 1,
        "node_index": 6
      }
    },
    {
      "node_id": "tb1_node7",
      "content": "For example, the lattice and duplation-and-mediation algorithms both solve the same problem: Given two non-negative integers $x$ and $y$ , each represented as an array of digits, compute the product $x cdot y$ , also represented as an array of digits. To someone using these algorithms, the choice of algorithm is completely irrelevant. On the other hand, the Greek straightedge-and-compass algorithm solves a different problem, because the input and output values are represented by line segments instead of arrays of digits. \nDescribing the Algorithm \nComputer programs are concrete representations of algorithms, but algorithms are not programs. Rather, algorithms are abstract mechanical procedures that can be implemented in any programming language that supports the underlying primitive operations. The idiosyncratic syntactic details of your favorite programming language are utterly irrelevant; focusing on these will only distract you (and your readers) from what’s really going on.20 A good algorithm description is closer to what we should write in the comments of a real program than the code itself. Code is a poor medium for storytelling. \nOn the other hand, a plain English prose description is usually not a good idea either. Algorithms have lots of idiomatic structure—especially conditionals, loops, function calls, and recursion—that are far too easily hidden by unstructured prose. Colloquial English is full of ambiguities and shades of meaning, but algorithms must be described as unambiguously as possible. Prose is a poor medium for precision. \nIn my opinion, the clearest way to present an algorithm is using a combination of pseudocode and structured English. Pseudocode uses the structure of formal programming languages and mathematics to break algorithms into primitive steps; the primitive steps themselves can be written using mathematical notation, pure English, or an appropriate mixture of the two, whatever is clearest. Wellwritten pseudocode reveals the internal structure of the algorithm but hides irrelevant implementation details, making the algorithm easier to understand, analyze, debug, and implement. \nWhenever we describe an algorithm, our description should include every detail necessary to fully specify the algorithm, prove its correctness, and analyze its running time. At the same time, it should exclude any details that are not necessary to fully specify the algorithm, prove its correctness, and analyze its running time. (Slide.) At a more practical level, our description should allow a competent but skeptical programmer who has not read this book to quickly and correctly implement the algorithm in their favorite programming language, without understanding why it works. \nI don’t want to bore you with the rules I follow for writing pseudocode, but I must caution against one especially pernicious habit. Never describe repeated operations informally, as in “Do [this] first, then do [that] second, and so on.” or “Repeat this process until [something]”. As anyone who has taken one of those frustrating “What comes next in this sequence?” tests already knows, describing the first few steps of an algorithm says little or nothing about what happens in later steps. If your algorithm has a loop, write it as a loop, and explicitly describe what happens in an arbitrary iteration. Similarly, if your algorithm is recursive, write it recursively, and explicitly describe the case boundaries and what happens in each case. \n0.6 Analyzing Algorithms \nIt’s not enough just to write down an algorithm and say “Behold!” We must also convince our audience (and ourselves!) that the algorithm actually does what it’s supposed to do, and that it does so efficiently. \nCorrectness \nIn some application settings, it is acceptable for programs to behave correctly most of the time, on all “reasonable” inputs. Not in this book; we require algorithms that are always correct, for all possible inputs. Moreover, we must prove that our algorithms are correct; trusting our instincts, or trying a few test cases, isn’t good enough. Sometimes correctness is truly obvious, especially for algorithms you’ve seen in earlier courses. On the other hand, “obvious” is all too often a synonym for “wrong”. Most of the algorithms we discuss in this course require real work to prove correct. In particular, correctness proofs usually involve induction. We like induction. Induction is our friend.21 \nOf course, before we can formally prove that our algorithm does what it’s supposed to do, we have to formally describe what it’s supposed to do!",
      "metadata": {
        "content": "For example, the lattice and duplation-and-mediation algorithms both solve the same problem: Given two non-negative integers $x$ and $y$ , each represented as an array of digits, compute the product $x cdot y$ , also represented as an array of digits. To someone using these algorithms, the choice of algorithm is completely irrelevant. On the other hand, the Greek straightedge-and-compass algorithm solves a different problem, because the input and output values are represented by line segments instead of arrays of digits. \nDescribing the Algorithm \nComputer programs are concrete representations of algorithms, but algorithms are not programs. Rather, algorithms are abstract mechanical procedures that can be implemented in any programming language that supports the underlying primitive operations. The idiosyncratic syntactic details of your favorite programming language are utterly irrelevant; focusing on these will only distract you (and your readers) from what’s really going on.20 A good algorithm description is closer to what we should write in the comments of a real program than the code itself. Code is a poor medium for storytelling. \nOn the other hand, a plain English prose description is usually not a good idea either. Algorithms have lots of idiomatic structure—especially conditionals, loops, function calls, and recursion—that are far too easily hidden by unstructured prose. Colloquial English is full of ambiguities and shades of meaning, but algorithms must be described as unambiguously as possible. Prose is a poor medium for precision. \nIn my opinion, the clearest way to present an algorithm is using a combination of pseudocode and structured English. Pseudocode uses the structure of formal programming languages and mathematics to break algorithms into primitive steps; the primitive steps themselves can be written using mathematical notation, pure English, or an appropriate mixture of the two, whatever is clearest. Wellwritten pseudocode reveals the internal structure of the algorithm but hides irrelevant implementation details, making the algorithm easier to understand, analyze, debug, and implement. \nWhenever we describe an algorithm, our description should include every detail necessary to fully specify the algorithm, prove its correctness, and analyze its running time. At the same time, it should exclude any details that are not necessary to fully specify the algorithm, prove its correctness, and analyze its running time. (Slide.) At a more practical level, our description should allow a competent but skeptical programmer who has not read this book to quickly and correctly implement the algorithm in their favorite programming language, without understanding why it works. \nI don’t want to bore you with the rules I follow for writing pseudocode, but I must caution against one especially pernicious habit. Never describe repeated operations informally, as in “Do [this] first, then do [that] second, and so on.” or “Repeat this process until [something]”. As anyone who has taken one of those frustrating “What comes next in this sequence?” tests already knows, describing the first few steps of an algorithm says little or nothing about what happens in later steps. If your algorithm has a loop, write it as a loop, and explicitly describe what happens in an arbitrary iteration. Similarly, if your algorithm is recursive, write it recursively, and explicitly describe the case boundaries and what happens in each case. \n0.6 Analyzing Algorithms \nIt’s not enough just to write down an algorithm and say “Behold!” We must also convince our audience (and ourselves!) that the algorithm actually does what it’s supposed to do, and that it does so efficiently. \nCorrectness \nIn some application settings, it is acceptable for programs to behave correctly most of the time, on all “reasonable” inputs. Not in this book; we require algorithms that are always correct, for all possible inputs. Moreover, we must prove that our algorithms are correct; trusting our instincts, or trying a few test cases, isn’t good enough. Sometimes correctness is truly obvious, especially for algorithms you’ve seen in earlier courses. On the other hand, “obvious” is all too often a synonym for “wrong”. Most of the algorithms we discuss in this course require real work to prove correct. In particular, correctness proofs usually involve induction. We like induction. Induction is our friend.21 \nOf course, before we can formally prove that our algorithm does what it’s supposed to do, we have to formally describe what it’s supposed to do!",
        "chapter": "Introduction",
        "section": "Describing Algorithms",
        "subsection": "Describing the Algorithm",
        "subsubsection": "N/A",
        "textbook_id": 1,
        "node_index": 7
      }
    },
    {
      "node_id": "tb1_node10",
      "content": "Finally, sometimes we are interested in computational resources other than time, such as space, number of coin flips, number of cache or page faults, number of inter-process messages, or the number of gifts my true love gave to me. These resources can be analyzed using the same techniques used to analyze running time. For example, lattice multiplication of two $n$ -digit numbers requires $O ( n ^ { 2 } )$ space if we write down all the partial products before adding them, but only $O ( n )$ space if we add them on the fly. \nExercises \n0. Describe and analyze an efficient algorithm that determines, given a legal arrangement of standard pieces on a standard chess board, which player will win at chess from the given starting position if both players play perfectly. [Hint: There is a trivial one-line solution!]   \nn1. (a) Identify (or write) a song that requires $Theta ( n ^ { 3 } )$ time to sing the first $n$ verses. (b) Identify (or write) a song that requires $Theta ( n log n )$ time to sing the first n verses. (c) Identify (or write) a song that requires some other weird amount of time to sing the first n verses. \n2. Careful readers might complain that our analysis of songs like $^ { * } n$ Bottles of Beer on the Wall” or “The n Days of Christmas” is overly simplistic, because larger numbers take longer to sing than shorter numbers. More generally, because there are only so many words of a given length, larger sets of words necessarily contain longer words.24 We can more accurately estimate singing time by counting the number of syllables sung, rather than the number of words. \n(a) How long does it take to sing the integer n? \n(b) How long does it take to sing “n Bottles of Beer on the Wall”? (c) How long does it take to sing “The $n$ Days of Christmas”? As usual, express your answers in the form $O ( f ( n ) )$ for some function $f$ . \n3. The cumulative drinking song “The Barley Mow” has been sung throughout the British Isles for centuries. The song has many variants; Figure 0.6 contains pseudolyrics for one version traditionally sung in Devon and Cornwall, where vessel[i] is the name of a vessel that holds $2 ^ { i }$ ounces of beer.25 \nBarleyMow(n): “Here’s a health to the barley-mow, my brave boys,” “Here’s a health to the barley-mow!” “We’ll drink it out of the jolly brown bowl,” “Here’s a health to the barley-mow!” “Here’s a health to the barley-mow, my brave boys,” “Here’s a health to the barley-mow!” for $i gets 1$ to n “We’ll drink it out of the vessel[i], boys,” “Here’s a health to the barley-mow!” for $j gets i$ downto 1 “The vessel[ j],” “And the jolly brown bowl!” “Here’s a health to the barley-mow!” “Here’s a health to the barley-mow, my brave boys,” “Here’s a health to the barley-mow!” \n(a) Suppose each name vessel[i] is a single word, and you can sing four words a second. How long would it take you to sing BarleyMow $( n ) ?$ (Give a tight asymptotic bound.)   \n(b) If you want to sing this song for arbitrarily large values of $n$ , you’ll have to make up your own vessel names. To avoid repetition, these names must become progressively longer as $n$ increases. Suppose vessel $[ n ]$ has \n$Theta ( log n )$ syllables, and you can sing six syllables per second. Now how long would it take you to sing BarleyMow $( n ) ?$ (Give a tight asymptotic bound.) \n(c) Suppose each time you mention the name of a vessel, you actually drink the corresponding amount of beer: one ounce for the jolly brown bowl, and $2 ^ { i }$ ounces for each vessel[i]. Assuming for purposes of this problem that you are at least 21 years old, exactly how many ounces of beer would you drink if you sang BarleyMow(n)? (Give an exact answer, not just an asymptotic bound.) \n4. Recall that the input to the Huntington-Hill algorithm ApportionCongress is an array $P o p [ 1 ldots n ]$ , where $P o p [ i ]$ is the population of the ith state, and an integer $R$ , the total number of representatives to be allotted. The output is an array $R e p [ 1 ldots n ]$ , where $R e p [ i ]$ is the number of representatives allotted to the ith state by the algorithm. \nThe Huntington-Hill algorithm is sometimes described in a way that avoids the use of priority queues entirely. The top-level algorithm “guesses” a positive real number $D$ , called the divisor, and then runs the following subroutine to compute an apportionment. The variable $q$ is the ideal quota of representatives allocated to a state for the given divisor $D$ ; the actual number of representatives allocated is always either $lceil q rceil$ or $lfloor q rfloor$ . \nThere are three possibilities for the final return value reps. If $r e p s < R$ , we did not allocate enough representatives, which (at least intuitively) means our divisor $D$ was too small. If $r e p s > R$ , we allocated too many representatives, which (at least intuitively) means our divisor $D$ was too large. Finally, if $r e p s = R$ , we can return the array $R e p [ 1 ldots n ]$ as the final apportionment. In practice, we can compute a valid apportionment (with $r e p s = R )$ ) by calling HHGuess with a small number of integer divisors close to the standard divisor $D = P / R$ . \nIn the following problems, let $begin{array} { r } { P = sum _ { i = 1 } ^ { n } P o p [ i ] } end{array}$ denote the total population of all $n$ states, and assume that $n leq R leq P$ . \n(a) Show that calling HHGuess with the standard divisor $D = P / R$ does not necessarily yield a valid apportionment.   \n(b) Prove that if HHGuess returns the same value of reps for two different divisors $D$ and $D ^ { prime }$ , it also computes the same allocation $R e p [ 1 ldots n ]$ for both of those divisors.   \n(c) Prove that if HHGuess returns the correct value $R$ , it computes the same allocation $R e p [ 1 . . n ]$ as our earlier algorithm ApportionCongress.   \n(d) Prove that a “correct” divisor $D$ does not necessarily exist! That is, describe inputs $P o p [ 1 ldots n ]$ and $R$ , where $n leq R leq P$ , such that for every real number $D > 0$ , the number of representatives allocated by HHGuess is not equal to $R$ . [Hint: What happens $i f$ we change $< t o le$ in the fourth line of HHGuess?] \nThe control of a large force is the same principle as the control of a few men: it is merely a question of dividing up their numbers. \n— Sun Zi, The Art of War (c. 400CE), translated by Lionel Giles (1910) \nOur life is frittered away by detail. . . . Simplify, simplify. — Henry David Thoreau, Walden (1854) \nNow, don’t ask me what Voom is. I never will know.   \nBut, boy! Let me tell you, it DOES clean up snow! — Dr. Seuss [Theodor Seuss Geisel], The Cat in the Hat Comes Back (1958) \nDo the hard jobs first. The easy jobs will take care of themselves \n— attributed to Dale Carnegie \nRecursion \n1.1 Reductions \nReduction is the single most common technique used in designing algorithms. Reducing one problem $X$ to another problem $Y$ means to write an algorithm for $X$ that uses an algorithm for $Y$ as a black box or subroutine. Crucially, the correctness of the resulting algorithm for $X$ cannot depend in any way on how the algorithm for $Y$ works. The only thing we can assume is that the black box solves $Y$ correctly. The inner workings of the black box are simply none of our business; they’re somebody else’s problem. It’s often best to literally think of the black box as functioning purely by magic. \nFor example, the peasant multiplication algorithm described in the previous chapter reduces the problem of multiplying two arbitrary positive integers to three simpler problems: addition, mediation (halving), and parity-checking. The algorithm relies on an abstract “positive integer” data type that supports those three operations, but the correctness of the multiplication algorithm does not depend on the precise data representation (tally marks, clay tokens, Babylonian hexagesimal, quipu, counting rods, Roman numerals, finger positions, augrym stones, gobar numerals, binary, negabinary, Gray code, balanced ternary, phinary, quater-imaginary, . . . ), or on the precise implementations of those operations. Of course, the running time of the multiplication algorithm depends on the running time of the addition, mediation, and parity operations, but that’s a separate issue from correctness. Most importantly, we can create a more efficient multiplication algorithm just by switching to a more efficient number representation (from tally marks to place-value notation, for example).",
      "metadata": {
        "content": "Finally, sometimes we are interested in computational resources other than time, such as space, number of coin flips, number of cache or page faults, number of inter-process messages, or the number of gifts my true love gave to me. These resources can be analyzed using the same techniques used to analyze running time. For example, lattice multiplication of two $n$ -digit numbers requires $O ( n ^ { 2 } )$ space if we write down all the partial products before adding them, but only $O ( n )$ space if we add them on the fly. \nExercises \n0. Describe and analyze an efficient algorithm that determines, given a legal arrangement of standard pieces on a standard chess board, which player will win at chess from the given starting position if both players play perfectly. [Hint: There is a trivial one-line solution!]   \nn1. (a) Identify (or write) a song that requires $Theta ( n ^ { 3 } )$ time to sing the first $n$ verses. (b) Identify (or write) a song that requires $Theta ( n log n )$ time to sing the first n verses. (c) Identify (or write) a song that requires some other weird amount of time to sing the first n verses. \n2. Careful readers might complain that our analysis of songs like $^ { * } n$ Bottles of Beer on the Wall” or “The n Days of Christmas” is overly simplistic, because larger numbers take longer to sing than shorter numbers. More generally, because there are only so many words of a given length, larger sets of words necessarily contain longer words.24 We can more accurately estimate singing time by counting the number of syllables sung, rather than the number of words. \n(a) How long does it take to sing the integer n? \n(b) How long does it take to sing “n Bottles of Beer on the Wall”? (c) How long does it take to sing “The $n$ Days of Christmas”? As usual, express your answers in the form $O ( f ( n ) )$ for some function $f$ . \n3. The cumulative drinking song “The Barley Mow” has been sung throughout the British Isles for centuries. The song has many variants; Figure 0.6 contains pseudolyrics for one version traditionally sung in Devon and Cornwall, where vessel[i] is the name of a vessel that holds $2 ^ { i }$ ounces of beer.25 \nBarleyMow(n): “Here’s a health to the barley-mow, my brave boys,” “Here’s a health to the barley-mow!” “We’ll drink it out of the jolly brown bowl,” “Here’s a health to the barley-mow!” “Here’s a health to the barley-mow, my brave boys,” “Here’s a health to the barley-mow!” for $i gets 1$ to n “We’ll drink it out of the vessel[i], boys,” “Here’s a health to the barley-mow!” for $j gets i$ downto 1 “The vessel[ j],” “And the jolly brown bowl!” “Here’s a health to the barley-mow!” “Here’s a health to the barley-mow, my brave boys,” “Here’s a health to the barley-mow!” \n(a) Suppose each name vessel[i] is a single word, and you can sing four words a second. How long would it take you to sing BarleyMow $( n ) ?$ (Give a tight asymptotic bound.)   \n(b) If you want to sing this song for arbitrarily large values of $n$ , you’ll have to make up your own vessel names. To avoid repetition, these names must become progressively longer as $n$ increases. Suppose vessel $[ n ]$ has \n$Theta ( log n )$ syllables, and you can sing six syllables per second. Now how long would it take you to sing BarleyMow $( n ) ?$ (Give a tight asymptotic bound.) \n(c) Suppose each time you mention the name of a vessel, you actually drink the corresponding amount of beer: one ounce for the jolly brown bowl, and $2 ^ { i }$ ounces for each vessel[i]. Assuming for purposes of this problem that you are at least 21 years old, exactly how many ounces of beer would you drink if you sang BarleyMow(n)? (Give an exact answer, not just an asymptotic bound.) \n4. Recall that the input to the Huntington-Hill algorithm ApportionCongress is an array $P o p [ 1 ldots n ]$ , where $P o p [ i ]$ is the population of the ith state, and an integer $R$ , the total number of representatives to be allotted. The output is an array $R e p [ 1 ldots n ]$ , where $R e p [ i ]$ is the number of representatives allotted to the ith state by the algorithm. \nThe Huntington-Hill algorithm is sometimes described in a way that avoids the use of priority queues entirely. The top-level algorithm “guesses” a positive real number $D$ , called the divisor, and then runs the following subroutine to compute an apportionment. The variable $q$ is the ideal quota of representatives allocated to a state for the given divisor $D$ ; the actual number of representatives allocated is always either $lceil q rceil$ or $lfloor q rfloor$ . \nThere are three possibilities for the final return value reps. If $r e p s < R$ , we did not allocate enough representatives, which (at least intuitively) means our divisor $D$ was too small. If $r e p s > R$ , we allocated too many representatives, which (at least intuitively) means our divisor $D$ was too large. Finally, if $r e p s = R$ , we can return the array $R e p [ 1 ldots n ]$ as the final apportionment. In practice, we can compute a valid apportionment (with $r e p s = R )$ ) by calling HHGuess with a small number of integer divisors close to the standard divisor $D = P / R$ . \nIn the following problems, let $begin{array} { r } { P = sum _ { i = 1 } ^ { n } P o p [ i ] } end{array}$ denote the total population of all $n$ states, and assume that $n leq R leq P$ . \n(a) Show that calling HHGuess with the standard divisor $D = P / R$ does not necessarily yield a valid apportionment.   \n(b) Prove that if HHGuess returns the same value of reps for two different divisors $D$ and $D ^ { prime }$ , it also computes the same allocation $R e p [ 1 ldots n ]$ for both of those divisors.   \n(c) Prove that if HHGuess returns the correct value $R$ , it computes the same allocation $R e p [ 1 . . n ]$ as our earlier algorithm ApportionCongress.   \n(d) Prove that a “correct” divisor $D$ does not necessarily exist! That is, describe inputs $P o p [ 1 ldots n ]$ and $R$ , where $n leq R leq P$ , such that for every real number $D > 0$ , the number of representatives allocated by HHGuess is not equal to $R$ . [Hint: What happens $i f$ we change $< t o le$ in the fourth line of HHGuess?] \nThe control of a large force is the same principle as the control of a few men: it is merely a question of dividing up their numbers. \n— Sun Zi, The Art of War (c. 400CE), translated by Lionel Giles (1910) \nOur life is frittered away by detail. . . . Simplify, simplify. — Henry David Thoreau, Walden (1854) \nNow, don’t ask me what Voom is. I never will know.   \nBut, boy! Let me tell you, it DOES clean up snow! — Dr. Seuss [Theodor Seuss Geisel], The Cat in the Hat Comes Back (1958) \nDo the hard jobs first. The easy jobs will take care of themselves \n— attributed to Dale Carnegie \nRecursion \n1.1 Reductions \nReduction is the single most common technique used in designing algorithms. Reducing one problem $X$ to another problem $Y$ means to write an algorithm for $X$ that uses an algorithm for $Y$ as a black box or subroutine. Crucially, the correctness of the resulting algorithm for $X$ cannot depend in any way on how the algorithm for $Y$ works. The only thing we can assume is that the black box solves $Y$ correctly. The inner workings of the black box are simply none of our business; they’re somebody else’s problem. It’s often best to literally think of the black box as functioning purely by magic. \nFor example, the peasant multiplication algorithm described in the previous chapter reduces the problem of multiplying two arbitrary positive integers to three simpler problems: addition, mediation (halving), and parity-checking. The algorithm relies on an abstract “positive integer” data type that supports those three operations, but the correctness of the multiplication algorithm does not depend on the precise data representation (tally marks, clay tokens, Babylonian hexagesimal, quipu, counting rods, Roman numerals, finger positions, augrym stones, gobar numerals, binary, negabinary, Gray code, balanced ternary, phinary, quater-imaginary, . . . ), or on the precise implementations of those operations. Of course, the running time of the multiplication algorithm depends on the running time of the addition, mediation, and parity operations, but that’s a separate issue from correctness. Most importantly, we can create a more efficient multiplication algorithm just by switching to a more efficient number representation (from tally marks to place-value notation, for example).",
        "chapter": "Introduction",
        "section": "Exercises",
        "subsection": "N/A",
        "subsubsection": "N/A",
        "textbook_id": 1,
        "node_index": 10
      }
    },
    {
      "node_id": "tb1_node11",
      "content": "The control of a large force is the same principle as the control of a few men: it is merely a question of dividing up their numbers. \n— Sun Zi, The Art of War (c. 400CE), translated by Lionel Giles (1910) \nOur life is frittered away by detail. . . . Simplify, simplify. — Henry David Thoreau, Walden (1854) \nNow, don’t ask me what Voom is. I never will know.   \nBut, boy! Let me tell you, it DOES clean up snow! — Dr. Seuss [Theodor Seuss Geisel], The Cat in the Hat Comes Back (1958) \nDo the hard jobs first. The easy jobs will take care of themselves \n— attributed to Dale Carnegie \nRecursion \n1.1 Reductions \nReduction is the single most common technique used in designing algorithms. Reducing one problem $X$ to another problem $Y$ means to write an algorithm for $X$ that uses an algorithm for $Y$ as a black box or subroutine. Crucially, the correctness of the resulting algorithm for $X$ cannot depend in any way on how the algorithm for $Y$ works. The only thing we can assume is that the black box solves $Y$ correctly. The inner workings of the black box are simply none of our business; they’re somebody else’s problem. It’s often best to literally think of the black box as functioning purely by magic. \nFor example, the peasant multiplication algorithm described in the previous chapter reduces the problem of multiplying two arbitrary positive integers to three simpler problems: addition, mediation (halving), and parity-checking. The algorithm relies on an abstract “positive integer” data type that supports those three operations, but the correctness of the multiplication algorithm does not depend on the precise data representation (tally marks, clay tokens, Babylonian hexagesimal, quipu, counting rods, Roman numerals, finger positions, augrym stones, gobar numerals, binary, negabinary, Gray code, balanced ternary, phinary, quater-imaginary, . . . ), or on the precise implementations of those operations. Of course, the running time of the multiplication algorithm depends on the running time of the addition, mediation, and parity operations, but that’s a separate issue from correctness. Most importantly, we can create a more efficient multiplication algorithm just by switching to a more efficient number representation (from tally marks to place-value notation, for example). \n\nSimilarly, the Huntington-Hill algorithm reduces the problem of apportioning Congress to the problem of maintaining a priority queue that supports the operations Insert and ExtractMax. The abstract data type “priority queue” is a black box; the correctness of the apportionment algorithm does not depend on any specific priority queue data structure. Of course, the running time of the apportionment algorithm depends on the running time of the Insert and ExtractMax algorithms, but that’s a separate issue from the correctness of the algorithm. The beauty of the reduction is that we can create a more efficient apportionment algorithm by simply swapping in a new priority queue data structure. Moreover, the designer of that data structure does not need to know or care that it will be used to apportion Congress. \nWhen we design algorithms, we may not know exactly how the basic building blocks we use are implemented, or how our algorithms might be used as building blocks to solve even bigger problems. That ignorance is uncomfortable for many beginners, but it is both unavoidable and extremely useful. Even when you do know precisely how your components work, it is often extremely helpful to pretend that you don’t. \n1.2 Simplify and Delegate \nRecursion is a particularly powerful kind of reduction, which can be described loosely as follows: \n• If the given instance of the problem can be solved directly, solve it directly.   \n• Otherwise, reduce it to one or more simpler instances of the same problem. \nIf the self-reference is confusing, it may be helpful to imagine that someone else is going to solve the simpler problems, just as you would assume for other types of reductions. I like to call that someone else the Recursion Fairy. Your only task is to simplify the original problem, or to solve it directly when simplification is either unnecessary or impossible; the Recursion Fairy will solve all the simpler subproblems for you, using Methods That Are None Of Your Business So Butt",
      "metadata": {
        "content": "The control of a large force is the same principle as the control of a few men: it is merely a question of dividing up their numbers. \n— Sun Zi, The Art of War (c. 400CE), translated by Lionel Giles (1910) \nOur life is frittered away by detail. . . . Simplify, simplify. — Henry David Thoreau, Walden (1854) \nNow, don’t ask me what Voom is. I never will know.   \nBut, boy! Let me tell you, it DOES clean up snow! — Dr. Seuss [Theodor Seuss Geisel], The Cat in the Hat Comes Back (1958) \nDo the hard jobs first. The easy jobs will take care of themselves \n— attributed to Dale Carnegie \nRecursion \n1.1 Reductions \nReduction is the single most common technique used in designing algorithms. Reducing one problem $X$ to another problem $Y$ means to write an algorithm for $X$ that uses an algorithm for $Y$ as a black box or subroutine. Crucially, the correctness of the resulting algorithm for $X$ cannot depend in any way on how the algorithm for $Y$ works. The only thing we can assume is that the black box solves $Y$ correctly. The inner workings of the black box are simply none of our business; they’re somebody else’s problem. It’s often best to literally think of the black box as functioning purely by magic. \nFor example, the peasant multiplication algorithm described in the previous chapter reduces the problem of multiplying two arbitrary positive integers to three simpler problems: addition, mediation (halving), and parity-checking. The algorithm relies on an abstract “positive integer” data type that supports those three operations, but the correctness of the multiplication algorithm does not depend on the precise data representation (tally marks, clay tokens, Babylonian hexagesimal, quipu, counting rods, Roman numerals, finger positions, augrym stones, gobar numerals, binary, negabinary, Gray code, balanced ternary, phinary, quater-imaginary, . . . ), or on the precise implementations of those operations. Of course, the running time of the multiplication algorithm depends on the running time of the addition, mediation, and parity operations, but that’s a separate issue from correctness. Most importantly, we can create a more efficient multiplication algorithm just by switching to a more efficient number representation (from tally marks to place-value notation, for example). \n\nSimilarly, the Huntington-Hill algorithm reduces the problem of apportioning Congress to the problem of maintaining a priority queue that supports the operations Insert and ExtractMax. The abstract data type “priority queue” is a black box; the correctness of the apportionment algorithm does not depend on any specific priority queue data structure. Of course, the running time of the apportionment algorithm depends on the running time of the Insert and ExtractMax algorithms, but that’s a separate issue from the correctness of the algorithm. The beauty of the reduction is that we can create a more efficient apportionment algorithm by simply swapping in a new priority queue data structure. Moreover, the designer of that data structure does not need to know or care that it will be used to apportion Congress. \nWhen we design algorithms, we may not know exactly how the basic building blocks we use are implemented, or how our algorithms might be used as building blocks to solve even bigger problems. That ignorance is uncomfortable for many beginners, but it is both unavoidable and extremely useful. Even when you do know precisely how your components work, it is often extremely helpful to pretend that you don’t. \n1.2 Simplify and Delegate \nRecursion is a particularly powerful kind of reduction, which can be described loosely as follows: \n• If the given instance of the problem can be solved directly, solve it directly.   \n• Otherwise, reduce it to one or more simpler instances of the same problem. \nIf the self-reference is confusing, it may be helpful to imagine that someone else is going to solve the simpler problems, just as you would assume for other types of reductions. I like to call that someone else the Recursion Fairy. Your only task is to simplify the original problem, or to solve it directly when simplification is either unnecessary or impossible; the Recursion Fairy will solve all the simpler subproblems for you, using Methods That Are None Of Your Business So Butt",
        "chapter": "Recursion",
        "section": "Reductions",
        "subsection": "N/A",
        "subsubsection": "N/A",
        "textbook_id": 1,
        "node_index": 11
      }
    }
  ],
  "output": {
    "question": "Which of the following best illustrates the principle of recursion as described in the context, where a complex problem is broken down into simpler, self-similar subproblems?",
    "correct_answer": "The control of a large force is the same principle as the control of a few men: it is merely a question of dividing up their numbers.",
    "distractors": [
      "Similar apportionment algorithms are used in multi-party parliamentary elections around the world, where the number of seats allocated to each party is supposed to be proportional to the number of votes that party receives.",
      "Your primary job as an algorithm designer is teaching other people how and why your algorithms work. If you can’t communicate your ideas to other human beings, they may as well not exist.",
      "Finally, sometimes we are interested in computational resources other than time, such as space, number of coin flips, number of cache or page faults, number of inter-process messages, or the number of gifts my true love gave to me."
    ],
    "rationale": "Step 1: Identified the Sun Zi quote from snippet [5] as the clearest analogy for recursion - controlling a large force by dividing it into smaller groups mirrors the recursive approach of solving a complex problem by breaking it into smaller, self-similar subproblems. Step 2: Selected three other snippets as distractors: [1] discusses proportional representation algorithms (not recursive in nature), [2] focuses on algorithm communication (not about problem decomposition), and [4] mentions alternative computational resources (unrelated to recursive structure). Step 3: Formulated the question to connect the recursive principle with the military analogy while maintaining the computer science examination context."
  },
  "score": {
    "relevance": 1.0,
    "faithfulness": 1.0,
    "integration": 0.0,
    "complexity": 0.5,
    "overall": 0.45000000000000007
  }
}