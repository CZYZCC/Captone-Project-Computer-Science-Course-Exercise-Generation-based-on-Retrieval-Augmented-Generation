{
  "context": [
    {
      "node_id": "tb1_node88",
      "content": "Exercises \nDepth-first search, topological sort, and strong components \n0. (a) Describe an algorithm to compute the reversal $r e nu ( G )$ of a directed graph in $O ( V + E )$ time. (b) Prove that for every directed graph $G$ , the strong component graph $s c c ( G )$ is acyclic. (c) Prove that $s c c ( r e nu ( G ) ) = r e nu ( s c c ( G ) )$ for every directed graph $G$ . (d) Fix an arbitrary directed graph $G$ . For any vertex $nu$ of $G$ , let $S ( nu )$ denote the strong component of $G$ that contains $nu$ . For all vertices $u$ and $nu$ of $G$ , prove that $u$ can reach $nu$ in $G$ if and only if $boldsymbol { S } ( boldsymbol { u } )$ can reach $S ( nu )$ in $s c c ( G )$ . \n1. A directed graph $G$ is semi-connected if, for every pair of vertices $u$ and $nu$ , either $u$ is reachable from $nu$ or $nu$ is reachable from $u$ (or both). \n(a) Give an example of a directed acyclic graph with a unique source that is not semi-connected.   \n(b) Describe and analyze an algorithm to determine whether a given directed acyclic graph is semi-connected. \n(c) Describe and analyze an algorithm to determine whether an arbitrary directed graph is semi-connected. \n2. The police department in the city of Sham-Poobanana has made every street in the city one-way. Despite widespread complaints from confused motorists, the mayor claims that it is possible to legally drive from any intersection in Sham-Poobanana to any other intersection. \n(a) The city needs to either verify or refute the mayor’s claim. Formalize this problem in terms of graphs, and then describe and analyze an algorithm to solve it.   \n(b) After running your algorithm from part (a), the mayor reluctantly admits that she was lying misinformed. Call an intersection $x$ good if, for any intersection $y$ that one can legally reach from $x$ , it is possible to legally drive from $y$ back to $x$ . Now the mayor claims that over $9 5 %$ of the intersections in Sham-Poobanana are good. Describe and analyze an efficient algorithm to verify or refute her claim. \nFor full credit, both algorithms should run in linear time. \n3. Suppose we are given a directed acyclic graph $G$ with a unique source s and a unique sink $t$ . A vertex $nu notin { s , t }$ is called an $( s , t )$ -cut vertex if every path from $s$ to $t$ passes through $nu$ , or equivalently, if deleting $nu$ makes $t$ unreachable from s. Describe and analyze an algorithm to find every $( s , t )$ -cut vertex in $G$ . \n4. A vertex $nu$ in a connected undirected graph $G$ is called a cut vertex if the subgraph $G - nu$ (obtained by removing $nu$ from $G$ ) is disconnected. \n(a) Describe a linear-time algorithm that determines, given an undirected graph $G$ and a vertex $nu$ , whether $nu$ is a cut vertex in $G$ . What is the running time to find all cut vertices by trying your algorithm for each vertex?   \n(b) Let $T$ be a depth-first spanning tree of an undirected graph $G$ . i. Prove that the root of $T$ is a cut vertex of $G$ if and only if it has more than one child in $T$ . ii. Prove that a non-root vertex $nu$ is a cut vertex of $G$ if and only if at least one descendant (in $T$ ) of each child of $nu$ (in $T$ ) is a neighbor (in $G$ ) of some proper ancestor of $nu$ (in $T$ ). [Hint: These claims no longer hold if $T$ not a depth-first spanning tree and/or $G$ is a directed graph.]   \n(c) Describe an algorithm that identifies every cut vertex in a given undirected graph in $O ( V + E )$ time. \n5. An edge e in a connected undirected graph $G$ is called a bridge (or a cut edge) if the subgraph $G - e$ (obtained by removing e from $G$ ) is disconnected. \n(a) Given $G$ and edge e describe a linear-time algorithm that determines whether $e$ is a bridge or not. What is the running time to find all bridges by trying your algorithm for each edge?   \n(b) Let $T$ be an arbitrary spanning tree of $G$ . Prove that every bridges of $G$ is also an edge in $T$ . This claim implies that $G$ has at most $V - 1$ bridges. How does this information improve your algorithm from part (a) to find all bridges?   \n(c) Now suppose we root $T$ at an arbitrary vertex $r$ . For any vertex $nu$ , let $T _ { nu }$ denote the subtree of $T$ rooted at $nu$ ; for example, $T _ { r } = T$ . Let $u nu$ be an arbitrary edge of $T$ , where $u$ is the parent of $nu$ . Prove that $u nu$ is a bridge of $G$ if and only if $u nu$ is the only edge in $G$ with exactly one endpoint in $T _ { nu }$ .   \n(d) Describe a linear-time algorithm to identify every bridge in $G$ . [Hint: Let $T$ be a depth-first spanning tree of G.] \n6. The transitive closure $G ^ { T }$ of a directed graph $G$ is a directed graph with the same vertices as $G$ , that contains any edge $u {  } nu$ if and only if there is a directed path from $u$ to $nu$ in $G$ . A transitive redu\u0001ction of $G$ is a graph with the smallest possible number of edges whose transitive closure is $G ^ { T }$ . The same graph may have several transitive reductions. \n(a) Describe an efficient algorithm to compute the transitive closure of a given directed graph. \n(b) Prove that a directed graph $G$ has a unique transitive reduction if and only if $G$ is acyclic.   \n(c) Describe an efficient algorithm to compute a transitive reduction of a given directed graph. \n7. One of the oldest algorithms for exploring arbitrary connected graphs was proposed by Gaston Tarry in 1895, as a systematic procedure for solving mazes.7 The input to Tarry’s algorithm is an undirected graph $G$ ; however, for ease of presentation, we formally split each undirected edge $u nu$ into two directed edges $u {  } nu$ and $nu {  } u$ . (In an actual implementation, this split is trivial; the algorit\u0001hm simply\u0001uses the given adjacency list for $G$ as though $G$ were directed.) \nWe informally say that Tarry’s algorithm “visits” vertex $nu$ every time it marks $nu$ , and it “traverses” edge $nu {  } w$ when it colors that edge red and recursively calls RecTarry $( w )$ . Unlike\u0001our earlier graph traversal algorithm, Tarry’s algorithm can mark same vertex multiple times. \n(a) Describe how to implement Tarry’s algorithm so that it runs in $O ( V + E )$ time.   \n(b) Prove that no directed edge in $G$ is traversed more than once.   \n(c) When the algorithm visits a vertex $nu$ for the $k$ th time, exactly how many edges into $nu$ are red, and exactly how many edges out of $nu$ are red? [Hint: Consider the starting vertex s separately from the other vertices.]   \n(d) Prove each vertex $nu$ is visited at most $deg ( nu )$ times, except the starting vertex s, which is visited at most $deg ( s ) + 1$ times. This claim immediately implies that Tarry $( G )$ terminates. \n(e) Prove that the last vertex visited by Tarry $( G )$ is the starting vertex s. \n(f) For every vertex $nu$ that Tarry $( G )$ visits, prove that all edges into $nu$ and out of $nu$ are red when Tarry $( G )$ halts. [Hint: Consider the vertices in the order that they are marked for the first time, starting with $s$ , and prove the claim by induction.]   \n(g) Prove that Tarry $( G )$ visits every vertex of $G$ . This claim and the previous claim imply that Tarry $( G )$ traverses every edge of $G$ exactly once. \n8. Consider the following variant of Tarry’s graph-traversal algorithm; this variant traverses green edges without recoloring them red and assigns two numerical labels to every vertex: \nProve or disprove the following claim: When Tarry2 $( G )$ halts, the green edges define a spanning tree and the labels $nu$ .pre and $nu$ .post define a preorder and postorder labeling that are all consistent with a single depth-first search of $G$ . In other words, prove or disprove that Tarry2 produces the same output as depth-first search, even though it visits the edges in a completely different order. \n9. You have a collection of $n$ lock-boxes and $m$ gold keys. Each key unlocks at most one box. However, each box might be unlocked by one key, by multiple keys, or by no keys at all. There are only two ways to open each box once it is locked: Unlock it properly (which requires having one matching key in your hand), or smash it to bits with a hammer. \nYour baby brother, who loves playing with shiny objects, has somehow managed to lock all your keys inside the boxes! Luckily, your home security system recorded everything, so you know exactly which keys (if any) are inside each box. You need to get all the keys back out of the boxes, because they are made of gold. Clearly you have to smash at least one box. \n(a) Your baby brother has found the hammer and is eagerly eyeing one of the boxes. Describe and analyze an algorithm to determine if it is \npossible to retrieve all the keys without smashing any box except the one your brother has chosen. (b) Describe and analyze an algorithm to compute the minimum number of boxes that must be smashed to retrieve all the keys. \n10. Suppose you are teaching an algorithms course. In your second midterm, you give your students a drawing of a graph and ask then to indicate a breadth-first search tree and a depth-first search tree rooted at a particular vertex. Unfortunately, once you start grading the exam, you realize that the graph you gave the students has several such spanning trees—far too many to list. Instead, you need a way to tell whether each student’s submission is correct! \nIn each of the following problems, suppose you are given a connected graph $G$ , a start vertex s, and a spanning tree $T$ of $G$ . \n(a) Suppose $G$ is undirected. Describe and analyze an algorithm to decide whether $T$ is a depth-first spanning tree rooted at $s$ .   \n(b) Suppose $G$ is undirected. Describe and analyze an algorithm to decide whether $T$ is a breadth-first spanning tree rooted at s. [Hint: It’s not enough for $T$ to be an unweighted shortest-path tree. Yes, this is the right chapter for this problem!]   \n(c) Suppose $G$ is directed. Describe and analyze an algorithm to decide whether $T$ is a breadth-first spanning tree rooted at s. [Hint: Solve part $( b )$ first.]   \n(d) Suppose $G$ is directed. Describe and analyze an algorithm to decide whether $T$ is a depth-first spanning tree rooted at $s$ . \n11. Several modern programming languages, including JavaScript, Python, Perl, and Ruby, include a feature called parallel assignment, which allows multiple assignment operations to be encoded in a single line of code. For example, the Python code $mathsf { x } , mathsf { y } = mathsf { 0 } , mathsf { 1 }$ simultaneously sets $x$ to 0 and y to 1. The values of the right-hand side of the assignment are all determined by the old values of the variables. Thus, the Python code a, ${ mathsf b } = { mathsf b }$ ,a swaps the values of a and b, and the following Python code computes the nth Fibonacci number: \ndef fib(n): prev, curr $= ~ 1$ , 0 while $n > 0$ : prev, curr, ${ mathfrak { n } } =$ curr, prev+curr, n-1 return curr \nSuppose the interpreter you are writing needs to convert every parallel assignment into an equivalent sequence of individual assignments. For example, the parallel assignment a, ${ bf b } = boldsymbol { 0 } , 1$ can be serialized in either order— either $a = 0$ ; $b = 1$ or $a = 0$ ; $b = 1$ —but the parallel assignment $mathsf { x } , mathsf { y } = mathsf { x } + 1$ , $x + y$ can only be serialized as $y = x + y$ ; $x = x + 1$ . Serialization may require one or more additional temporary variables; for example, serializing a, $b = 6$ ,a requires one temporary variable, and serializing $x , y = x { + } y$ , $x - y$ requires two temporary variables. \n\n(a) Describe an algorithm to determine whether a given parallel assignment can be serialized without additional temporary variables.   \n(b) Describe an algorithm to determine whether a given parallel assignment can be serialized with exactly one additional temporary variable. \nAssume that the given parallel assignment involves only simple integer variables (no indirection via pointers or arrays); no variable appears on the left side more than once; and expressions on the right side have no side effects. Don’t worry about the details of parsing the assignment statement; just assume (but describe!) an appropriate graph representation. \nDynamic Programming \n12. Suppose we are given a directed acyclic graph $G$ whose nodes represent jobs and whose edges represent precedence constraints; that is. each edge $u {  } nu$ indicates the job $u$ must be completed before job $nu$ begins. Each node $nu$ al\u0001so has a weight $T ( nu )$ indicating the time required to execute job $nu$ . \n(a) Describe an algorithm to determine the shortest interval of time in which all jobs in $G$ can be executed.   \n(b) Suppose the first job starts at time 0. Describe an algorithm to determine, for each vertex $nu$ , the earliest time when job $nu$ can begin.   \n(c) Now describe an algorithm to determine, for each vertex $nu$ , the latest time when job $nu$ can begin without violating the precedence constraints or increasing the overall completion time (computed in part (a)), assuming that every job except $nu$ starts at its earliest start time (computed in part (b)). \n13. Let $G$ be a directed acyclic graph with a unique source s and a unique sink $t$ . \n(a) A Hamiltonian path in $G$ is a directed path in $G$ that contains every vertex in $G$ . Describe an algorithm to determine whether $G$ has a Hamiltonian path.   \n(b) Suppose the vertices of $G$ have weights. Describe an efficient algorithm to find the path from $s$ to $t$ with maximum total weight.   \n(c) Suppose we are also given an integer $ell$ . Describe an efficient algorithm to find the maximum-weight path from $s$ to $t$ that contains at most $ell$ edges. (Assume there is at least one such path.)   \n(d) Suppose some of the vertices of $G$ are marked as important, and we are also given an integer $k$ . Describe an efficient algorithm to find the maximum-weight path from s to $t$ that visits at least $k$ important vertices. (Assume there is at least one such path.)   \n(e) Describe an algorithm to compute the number of paths from s to $t$ in $G$ . (Assume that you can add arbitrarily large integers in $O ( 1 )$ time.) \n\n14. Let $G$ be a directed acyclic graph whose vertices have labels from some fixed alphabet, and let $A [ 1 ldots ell ]$ be a string over the same alphabet. Any directed path in $G$ has a label, which is a string obtained by concatenating the labels of its vertices. \n(a) Describe an algorithm that either finds a path in $G$ whose label is $A$ or correctly reports that there is no such path.   \n(b) Describe an algorithm to find the number of paths in $G$ whose label is $A$ . (Assume that you can add arbitrarily large integers in $O ( 1 )$ time.)   \n(c) Describe an algorithm to find the longest path in $G$ whose label is a subsequence of A.   \n(d) Describe an algorithm to find the shortest path in $G$ whose label is a supersequence of A.   \n(e) Describe an algorithm to find a path in $G$ whose label has minimum edit distance from A. \n15. A polygonal path is a sequence of line segments joined end-to-end; the endpoints of these line segments are called the vertices of the path. The length of a polygonal path is the sum of the lengths of its segments. A polygonal path with vertices $( x _ { 1 } , y _ { 1 } ) , ( x _ { 2 } , y _ { 2 } ) , ldots , ( x _ { k } , y _ { k } )$ is monotonically increasing if $x _ { i } < x _ { i + 1 }$ and $y _ { i } < y _ { i + 1 }$ for every index $i$ —informally, each vertex of the path is above and to the right of its predecessor. \nSuppose you are given a set $s$ of $n$ points in the plane, represented as two arrays $X [ 1 ldots n ]$ and $Y [ 1 ldots n ]$ . Describe and analyze an algorithm to compute the length of the longest monotonically increasing path with vertices in $s$ . Assume you have a subroutine $mathrm { L E N G T H } ( x , y , x ^ { prime } , y ^ { prime } )$ that returns the length of the segment from $( x , y )$ to $( x ^ { prime } , y ^ { prime } )$ . \n16. For any two nodes $u$ and $w$ in a directed acyclic graph $G$ , the interval $G [ u , w ]$ is the union of all directed paths in $G$ from $u$ to $nu$ . Equivalently, $G [ u , w ]$ consists of all vertices $nu$ such that $nu in r e a c h ( u )$ and $w in r e a c h ( x )$ , together with all the edges in $G$ connecting those vertices. \nSuppose we are given a directed acyclic graph $G$ , in which every vertex has a numerical weight, which may be positive, negative, or zero. \n(a) Describe an efficient algorithm to find the maximum-weight interval in $G$ , where the weight of each interval is the sum of the weights of its vertices.   \n(b) Describe an efficient algorithm to find the largest vertex weight in every interval in $G$ . Your algorithm should compute a two-dimensional array $M a x W t [ 1 ldots V , 1 ldots V ]$ where each entry $M a x W t [ u , w ]$ is the maximum weight among all vertices in the interval $G [ u , w ]$ . In particular, if $G [ u , w ]$ is empty, then $M a x W t [ u , w ]$ should be $- infty$ . \n17. Let $G$ be a directed acyclic graph whose vertices have labels from some fixed alphabet. Any directed path in $G$ has a label, which is a string obtained by concatenating the labels of its vertices. Recall that a palindrome is a string that is equal to its reversal. \n(a) Describe and analyze an algorithm to find the length of the longest palindrome that is the label of a path in $G$ . For example, given the graph in Figure 6.23, your algorithm should return the integer 6, which is the length of the palindrome HANNAH. \n(b) Describe an algorithm to find the longest palindrome that is a subsequence of the label of a path in $G$ .   \n(c) Suppose $G$ has a single source s and a single sink t. Describe an algorithm to find the shortest palindrome that is a supersequence of the label of a path in $G$ from $s$ to $t$ . \n18. Suppose you are given two directed acyclic graphs $G$ and $H$ in which every node has a label from some finite alphabet; different nodes may have the same label. The label of a path in either dag is the string obtained by concatenating the labels of its vertices. \n(a) Describe and analyze an algorithm to compute the length of the longest string that is both the label of a path in $G$ and the label of a path in $H$ .   \n(b) Describe and analyze an algorithm to compute the length of the longest string that is both a subsequence of the label of a path in $G$ and a subsequence of the label of a path in $H$ .   \n(c) Describe and analyze an algorithm to compute the length of the shortest string that is both a supersequence of the label of a path in $G$ and a supersequence of the label of a path in $H$ . [Hint: This is easier than it looks.] \n19. Let $G$ be an arbitrary (not necessarily acyclic) directed graph in which every vertex $nu$ has an integer weight $w ( nu )$ . \n(a) Describe an algorithm to find the longest directed path in $G$ whose vertex weights define an increasing sequence.   \n(b) Describe and analyze an algorithm to determine the maximum-weight vertex reachable from each vertex in $G$ . That is, for each vertex $nu$ , your algorithm needs to compute maxreach $( nu ) : = operatorname* { m a x } { w ( x ) mid x in r e a c h ( nu ) }$ . \n20. (a) Suppose you are given a directed acyclic graph $G$ with $n$ vertices and an integer $k leq n$ . Describe an efficient algorithm to find a set of at most $k$ vertex-disjoint paths that visit every vertex in $G$ . (b) Now suppose the edges of the input dag $G$ have weights, which may be positive, negative, or zero. Describe an efficient algorithm to find a set of at most $k$ vertex-disjoint paths with minimum total weight that visit every vertex in $G$ . \nYour algorithms should run in $O ( n ^ { k + c } )$ time for some small constant c. A single vertex is a path with weight zero. (We will see a more efficient algorithm for part (a) in Chapter 11.) \n21. Kris is a professional rock climber who is competing in the U.S. climbing nationals. The competition requires Kris to use as many holds on the climbing wall as possible, using only transitions that have been explicitly allowed by the route-setter. \nThe climbing wall has $n$ holds. Kris is given a list of $m$ pairs $( x , y )$ of holds, each indicating that moving directly from hold $x$ to hold $y$ is allowed; however, moving directly from $y$ to $x$ is not allowed unless the list also includes the pair $( y , x )$ . Kris needs to figure out a sequence of allowed transitions that uses as many holds as possible, since each new hold increases his score by one point. The rules allow Kris to choose the first and last hold in his climbing route. The rules also allow him to use each hold as many times as he likes; however, only the first use of each hold increases Kris’s score. \n(a) Define the natural graph representing the input. Describe and analyze an algorithm to solve Kris’s climbing problem if you are guaranteed that the input graph is a dag.   \n(b) Describe and analyze an algorithm to solve Kris’s climbing problem with no restrictions on the input graph. \nBoth of your algorithms should output the maximum possible score that Kris can earn. \n22. There are $n$ galaxies connected by $m$ intergalactic teleport-ways. Each teleport-way joins two galaxies and can be traversed in both directions. However, the company that runs the teleport-ways has established an extremely lucrative cost structure: Anyone can teleport further from their home galaxy at no cost whatsoever, but teleporting toward their home galaxy is prohibitively expensive. \nJudy has decided to take a sabbatical tour of the universe by visiting as many galaxies as possible, starting at her home galaxy. To save on travel expenses, she wants to teleport away from her home galaxy at every step, except for the very last teleport home. \n(a) Describe and analyze an algorithm to compute the maximum number of galaxies that Judy can visit. Your input consists of an undirected graph $G$ with $n$ vertices and $m$ edges describing the teleport-way network, an integer $1 leq s leq n$ identifying Judy’s home galaxy, and an array $D [ 1 ldots n ]$ containing the distances of each galaxy from s.   \nn(b) Just before embarking on her universal tour, Judy wins the space lottery, giving her just enough money to afford two teleports toward her home galaxy. Describe a new algorithm to compute the maximum number of distinct galaxies Judy can visit. She can visit the same galaxy more than once, but crucially, only the first visit counts toward her total. \n23. The Doctor and River Song decide to play a game on a directed acyclic graph $G$ , which has one source $s$ and one sink $t$ .8 \nEach player has a token on one of the vertices of $G$ . At the start of the game, The Doctor’s token is on the source vertex s, and River’s token is on the sink vertex t. The players alternate turns, with The Doctor moving first. On each of his turns, the Doctor moves his token forward along a directed edge; on each of her turns, River moves her token backward along a directed edge. \nIf the two tokens ever meet on the same vertex, River wins the game. (“Hello, Sweetie!”) If the Doctor’s token reaches t or River’s token reaches s before the two tokens meet, then the Doctor wins the game. \nDescribe and analyze an algorithm to determine who wins this game, assuming both players play perfectly. That is, if the Doctor can win no matter how River moves, then your algorithm should output “Doctor”, and if River can win no matter how the Doctor moves, your algorithm should output “River”. (Why are these the only two possibilities?) The input to your algorithm is the graph $G$ . \n$a v _ { 2 4 }$ . Let $x = x _ { 1 } x _ { 2 } ldots x _ { n }$ be a given $n$ -character string over some finite alphabet $Sigma$ , and let $A$ be a deterministic finite-state machine with m states over the same alphabet. \n(a) Describe and analyze an algorithm to compute the length of the longest subsequence of $x$ that is accepted by $A .$ . For example, if A accepts the language $( mathsf { A R } ) ^ { * }$ and $x =$ ABRACADABRA, your algorithm should output the number 4, which is the length of the subsequence ARAR.   \n(b) Describe and analyze an algorithm to compute the length of the shortest supersequence of $x$ that is accepted by $A$ . For example, if $A$ accepts the language (ABCDR)∗ and $x =$ ABRACADABRA, your algorithm should output the number 25, which is the length of the supersequence ABCDRABCDRABCDRABCDRABCDR. \nAnalyze your algorithms in terms of the length $n$ of the input string, the number m of states in the finite-state machine, and the size of the alphabet $Sigma$ . \n25. Not every dynamic programming algorithm can be modeled as finding an optimal path through a directed acyclic graph, but every dynamic programming algorithm does process some underlying dependency graph in postorder. \n(a) Suppose we are given a directed acyclic graph $G$ where every node stores a numerical search key. Describe and analyze an algorithm to find the largest binary search tree that is a subgraph of $G$ .   \n(b) Suppose we are given a directed acyclic graph $G$ and two vertices $s$ and $t$ . Describe an algorithm to compute the number of directed paths in $G$ from s to $t$ . (Assume that any arithmetic operation requires $O ( 1 )$ time.) \n(c) Let $G$ be a directed acyclic graph with the following features: \n• $G$ has a single source $s$ and several sinks $t _ { 1 } , t _ { 2 } , ldots , t _ { k }$ . • Each edge $nu {  } w$ has an associated weight $p ( nu {  } w )$ between 0 and 1. • For each non\u0001-sink vertex $nu$ , the total weight \u0001of all edges leaving $nu$ is 1; that is, $begin{array} { r } { sum _ { w } p ( nu to w ) = 1 } end{array}$ . \nThe weights $p ( nu {  } w )$ defi\u0001ne a random walk in $G$ from the source $s$ to some sink $t _ { i }$ ; after reac\u0001hing any non-sink vertex $nu$ , the walk follows edge $nu {  } w$ with probability $p ( nu {  } w )$ . All probabilities are mutually independe\u0001nt. Describe and analyze\u0001an algorithm to compute the probability that this random walk reaches sink $t _ { i }$ , for every index i. (Assume that each arithmetic operation takes only $O ( 1 )$ time.) \nWe must all hang together, gentlemen, or else we shall most assuredly hang separately. \n— Benjamin Franklin, at the signing of the Declaration of Independence (July 4, 1776) \nI remember seeking advice from someone—who could it have been?—about whether this work was worth submitting for publication; the reasoning it uses is so very simple....Fortunately he advised me to go ahead, and many years passed before another of my publications became as well-known as this very simple one. \n— Joseph Kruskal, describing his shortest-spanning-subtree algorithm (1997) \nClean ALL the things! \n— Allie Brosh, “This is Why I’ll Never be an Adult”, Hyperbole and a Half, June 17, 2010. \nMinimum Spanning Trees \nSuppose we are given a connected, undirected, weighted graph. This is a graph $G = ( V , E )$ together with a function $boldsymbol { w } colon boldsymbol { E } to mathbb { R }$ that assigns a real weight $w ( e )$ to each edge $e$ , which may be positive, negative, or zero. This chapter describes several algorithms to find the minimum spanning tree of $G$ , that is, the spanning tree $T$ that minimizes the function \nSee Figure 7.1 for an example. \n7.1 Distinct Edge Weights \nAn annoying subtlety in the problem statement is that weighted graphs can have more than one spanning tree with the same minimum weight; in particular, if every edge in $G$ has weight 1, then every spanning tree of $G$ is a minimum spanning tree, with weight $V - 1$ . This ambiguity complicates the development of our algorithms; everything would be much simpler if we could simply assume that minimum spanning trees are unique.",
      "metadata": {
        "content": "Exercises \nDepth-first search, topological sort, and strong components \n0. (a) Describe an algorithm to compute the reversal $r e nu ( G )$ of a directed graph in $O ( V + E )$ time. (b) Prove that for every directed graph $G$ , the strong component graph $s c c ( G )$ is acyclic. (c) Prove that $s c c ( r e nu ( G ) ) = r e nu ( s c c ( G ) )$ for every directed graph $G$ . (d) Fix an arbitrary directed graph $G$ . For any vertex $nu$ of $G$ , let $S ( nu )$ denote the strong component of $G$ that contains $nu$ . For all vertices $u$ and $nu$ of $G$ , prove that $u$ can reach $nu$ in $G$ if and only if $boldsymbol { S } ( boldsymbol { u } )$ can reach $S ( nu )$ in $s c c ( G )$ . \n1. A directed graph $G$ is semi-connected if, for every pair of vertices $u$ and $nu$ , either $u$ is reachable from $nu$ or $nu$ is reachable from $u$ (or both). \n(a) Give an example of a directed acyclic graph with a unique source that is not semi-connected.   \n(b) Describe and analyze an algorithm to determine whether a given directed acyclic graph is semi-connected. \n(c) Describe and analyze an algorithm to determine whether an arbitrary directed graph is semi-connected. \n2. The police department in the city of Sham-Poobanana has made every street in the city one-way. Despite widespread complaints from confused motorists, the mayor claims that it is possible to legally drive from any intersection in Sham-Poobanana to any other intersection. \n(a) The city needs to either verify or refute the mayor’s claim. Formalize this problem in terms of graphs, and then describe and analyze an algorithm to solve it.   \n(b) After running your algorithm from part (a), the mayor reluctantly admits that she was lying misinformed. Call an intersection $x$ good if, for any intersection $y$ that one can legally reach from $x$ , it is possible to legally drive from $y$ back to $x$ . Now the mayor claims that over $9 5 %$ of the intersections in Sham-Poobanana are good. Describe and analyze an efficient algorithm to verify or refute her claim. \nFor full credit, both algorithms should run in linear time. \n3. Suppose we are given a directed acyclic graph $G$ with a unique source s and a unique sink $t$ . A vertex $nu notin { s , t }$ is called an $( s , t )$ -cut vertex if every path from $s$ to $t$ passes through $nu$ , or equivalently, if deleting $nu$ makes $t$ unreachable from s. Describe and analyze an algorithm to find every $( s , t )$ -cut vertex in $G$ . \n4. A vertex $nu$ in a connected undirected graph $G$ is called a cut vertex if the subgraph $G - nu$ (obtained by removing $nu$ from $G$ ) is disconnected. \n(a) Describe a linear-time algorithm that determines, given an undirected graph $G$ and a vertex $nu$ , whether $nu$ is a cut vertex in $G$ . What is the running time to find all cut vertices by trying your algorithm for each vertex?   \n(b) Let $T$ be a depth-first spanning tree of an undirected graph $G$ . i. Prove that the root of $T$ is a cut vertex of $G$ if and only if it has more than one child in $T$ . ii. Prove that a non-root vertex $nu$ is a cut vertex of $G$ if and only if at least one descendant (in $T$ ) of each child of $nu$ (in $T$ ) is a neighbor (in $G$ ) of some proper ancestor of $nu$ (in $T$ ). [Hint: These claims no longer hold if $T$ not a depth-first spanning tree and/or $G$ is a directed graph.]   \n(c) Describe an algorithm that identifies every cut vertex in a given undirected graph in $O ( V + E )$ time. \n5. An edge e in a connected undirected graph $G$ is called a bridge (or a cut edge) if the subgraph $G - e$ (obtained by removing e from $G$ ) is disconnected. \n(a) Given $G$ and edge e describe a linear-time algorithm that determines whether $e$ is a bridge or not. What is the running time to find all bridges by trying your algorithm for each edge?   \n(b) Let $T$ be an arbitrary spanning tree of $G$ . Prove that every bridges of $G$ is also an edge in $T$ . This claim implies that $G$ has at most $V - 1$ bridges. How does this information improve your algorithm from part (a) to find all bridges?   \n(c) Now suppose we root $T$ at an arbitrary vertex $r$ . For any vertex $nu$ , let $T _ { nu }$ denote the subtree of $T$ rooted at $nu$ ; for example, $T _ { r } = T$ . Let $u nu$ be an arbitrary edge of $T$ , where $u$ is the parent of $nu$ . Prove that $u nu$ is a bridge of $G$ if and only if $u nu$ is the only edge in $G$ with exactly one endpoint in $T _ { nu }$ .   \n(d) Describe a linear-time algorithm to identify every bridge in $G$ . [Hint: Let $T$ be a depth-first spanning tree of G.] \n6. The transitive closure $G ^ { T }$ of a directed graph $G$ is a directed graph with the same vertices as $G$ , that contains any edge $u {  } nu$ if and only if there is a directed path from $u$ to $nu$ in $G$ . A transitive redu\u0001ction of $G$ is a graph with the smallest possible number of edges whose transitive closure is $G ^ { T }$ . The same graph may have several transitive reductions. \n(a) Describe an efficient algorithm to compute the transitive closure of a given directed graph. \n(b) Prove that a directed graph $G$ has a unique transitive reduction if and only if $G$ is acyclic.   \n(c) Describe an efficient algorithm to compute a transitive reduction of a given directed graph. \n7. One of the oldest algorithms for exploring arbitrary connected graphs was proposed by Gaston Tarry in 1895, as a systematic procedure for solving mazes.7 The input to Tarry’s algorithm is an undirected graph $G$ ; however, for ease of presentation, we formally split each undirected edge $u nu$ into two directed edges $u {  } nu$ and $nu {  } u$ . (In an actual implementation, this split is trivial; the algorit\u0001hm simply\u0001uses the given adjacency list for $G$ as though $G$ were directed.) \nWe informally say that Tarry’s algorithm “visits” vertex $nu$ every time it marks $nu$ , and it “traverses” edge $nu {  } w$ when it colors that edge red and recursively calls RecTarry $( w )$ . Unlike\u0001our earlier graph traversal algorithm, Tarry’s algorithm can mark same vertex multiple times. \n(a) Describe how to implement Tarry’s algorithm so that it runs in $O ( V + E )$ time.   \n(b) Prove that no directed edge in $G$ is traversed more than once.   \n(c) When the algorithm visits a vertex $nu$ for the $k$ th time, exactly how many edges into $nu$ are red, and exactly how many edges out of $nu$ are red? [Hint: Consider the starting vertex s separately from the other vertices.]   \n(d) Prove each vertex $nu$ is visited at most $deg ( nu )$ times, except the starting vertex s, which is visited at most $deg ( s ) + 1$ times. This claim immediately implies that Tarry $( G )$ terminates. \n(e) Prove that the last vertex visited by Tarry $( G )$ is the starting vertex s. \n(f) For every vertex $nu$ that Tarry $( G )$ visits, prove that all edges into $nu$ and out of $nu$ are red when Tarry $( G )$ halts. [Hint: Consider the vertices in the order that they are marked for the first time, starting with $s$ , and prove the claim by induction.]   \n(g) Prove that Tarry $( G )$ visits every vertex of $G$ . This claim and the previous claim imply that Tarry $( G )$ traverses every edge of $G$ exactly once. \n8. Consider the following variant of Tarry’s graph-traversal algorithm; this variant traverses green edges without recoloring them red and assigns two numerical labels to every vertex: \nProve or disprove the following claim: When Tarry2 $( G )$ halts, the green edges define a spanning tree and the labels $nu$ .pre and $nu$ .post define a preorder and postorder labeling that are all consistent with a single depth-first search of $G$ . In other words, prove or disprove that Tarry2 produces the same output as depth-first search, even though it visits the edges in a completely different order. \n9. You have a collection of $n$ lock-boxes and $m$ gold keys. Each key unlocks at most one box. However, each box might be unlocked by one key, by multiple keys, or by no keys at all. There are only two ways to open each box once it is locked: Unlock it properly (which requires having one matching key in your hand), or smash it to bits with a hammer. \nYour baby brother, who loves playing with shiny objects, has somehow managed to lock all your keys inside the boxes! Luckily, your home security system recorded everything, so you know exactly which keys (if any) are inside each box. You need to get all the keys back out of the boxes, because they are made of gold. Clearly you have to smash at least one box. \n(a) Your baby brother has found the hammer and is eagerly eyeing one of the boxes. Describe and analyze an algorithm to determine if it is \npossible to retrieve all the keys without smashing any box except the one your brother has chosen. (b) Describe and analyze an algorithm to compute the minimum number of boxes that must be smashed to retrieve all the keys. \n10. Suppose you are teaching an algorithms course. In your second midterm, you give your students a drawing of a graph and ask then to indicate a breadth-first search tree and a depth-first search tree rooted at a particular vertex. Unfortunately, once you start grading the exam, you realize that the graph you gave the students has several such spanning trees—far too many to list. Instead, you need a way to tell whether each student’s submission is correct! \nIn each of the following problems, suppose you are given a connected graph $G$ , a start vertex s, and a spanning tree $T$ of $G$ . \n(a) Suppose $G$ is undirected. Describe and analyze an algorithm to decide whether $T$ is a depth-first spanning tree rooted at $s$ .   \n(b) Suppose $G$ is undirected. Describe and analyze an algorithm to decide whether $T$ is a breadth-first spanning tree rooted at s. [Hint: It’s not enough for $T$ to be an unweighted shortest-path tree. Yes, this is the right chapter for this problem!]   \n(c) Suppose $G$ is directed. Describe and analyze an algorithm to decide whether $T$ is a breadth-first spanning tree rooted at s. [Hint: Solve part $( b )$ first.]   \n(d) Suppose $G$ is directed. Describe and analyze an algorithm to decide whether $T$ is a depth-first spanning tree rooted at $s$ . \n11. Several modern programming languages, including JavaScript, Python, Perl, and Ruby, include a feature called parallel assignment, which allows multiple assignment operations to be encoded in a single line of code. For example, the Python code $mathsf { x } , mathsf { y } = mathsf { 0 } , mathsf { 1 }$ simultaneously sets $x$ to 0 and y to 1. The values of the right-hand side of the assignment are all determined by the old values of the variables. Thus, the Python code a, ${ mathsf b } = { mathsf b }$ ,a swaps the values of a and b, and the following Python code computes the nth Fibonacci number: \ndef fib(n): prev, curr $= ~ 1$ , 0 while $n > 0$ : prev, curr, ${ mathfrak { n } } =$ curr, prev+curr, n-1 return curr \nSuppose the interpreter you are writing needs to convert every parallel assignment into an equivalent sequence of individual assignments. For example, the parallel assignment a, ${ bf b } = boldsymbol { 0 } , 1$ can be serialized in either order— either $a = 0$ ; $b = 1$ or $a = 0$ ; $b = 1$ —but the parallel assignment $mathsf { x } , mathsf { y } = mathsf { x } + 1$ , $x + y$ can only be serialized as $y = x + y$ ; $x = x + 1$ . Serialization may require one or more additional temporary variables; for example, serializing a, $b = 6$ ,a requires one temporary variable, and serializing $x , y = x { + } y$ , $x - y$ requires two temporary variables. \n\n(a) Describe an algorithm to determine whether a given parallel assignment can be serialized without additional temporary variables.   \n(b) Describe an algorithm to determine whether a given parallel assignment can be serialized with exactly one additional temporary variable. \nAssume that the given parallel assignment involves only simple integer variables (no indirection via pointers or arrays); no variable appears on the left side more than once; and expressions on the right side have no side effects. Don’t worry about the details of parsing the assignment statement; just assume (but describe!) an appropriate graph representation. \nDynamic Programming \n12. Suppose we are given a directed acyclic graph $G$ whose nodes represent jobs and whose edges represent precedence constraints; that is. each edge $u {  } nu$ indicates the job $u$ must be completed before job $nu$ begins. Each node $nu$ al\u0001so has a weight $T ( nu )$ indicating the time required to execute job $nu$ . \n(a) Describe an algorithm to determine the shortest interval of time in which all jobs in $G$ can be executed.   \n(b) Suppose the first job starts at time 0. Describe an algorithm to determine, for each vertex $nu$ , the earliest time when job $nu$ can begin.   \n(c) Now describe an algorithm to determine, for each vertex $nu$ , the latest time when job $nu$ can begin without violating the precedence constraints or increasing the overall completion time (computed in part (a)), assuming that every job except $nu$ starts at its earliest start time (computed in part (b)). \n13. Let $G$ be a directed acyclic graph with a unique source s and a unique sink $t$ . \n(a) A Hamiltonian path in $G$ is a directed path in $G$ that contains every vertex in $G$ . Describe an algorithm to determine whether $G$ has a Hamiltonian path.   \n(b) Suppose the vertices of $G$ have weights. Describe an efficient algorithm to find the path from $s$ to $t$ with maximum total weight.   \n(c) Suppose we are also given an integer $ell$ . Describe an efficient algorithm to find the maximum-weight path from $s$ to $t$ that contains at most $ell$ edges. (Assume there is at least one such path.)   \n(d) Suppose some of the vertices of $G$ are marked as important, and we are also given an integer $k$ . Describe an efficient algorithm to find the maximum-weight path from s to $t$ that visits at least $k$ important vertices. (Assume there is at least one such path.)   \n(e) Describe an algorithm to compute the number of paths from s to $t$ in $G$ . (Assume that you can add arbitrarily large integers in $O ( 1 )$ time.) \n\n14. Let $G$ be a directed acyclic graph whose vertices have labels from some fixed alphabet, and let $A [ 1 ldots ell ]$ be a string over the same alphabet. Any directed path in $G$ has a label, which is a string obtained by concatenating the labels of its vertices. \n(a) Describe an algorithm that either finds a path in $G$ whose label is $A$ or correctly reports that there is no such path.   \n(b) Describe an algorithm to find the number of paths in $G$ whose label is $A$ . (Assume that you can add arbitrarily large integers in $O ( 1 )$ time.)   \n(c) Describe an algorithm to find the longest path in $G$ whose label is a subsequence of A.   \n(d) Describe an algorithm to find the shortest path in $G$ whose label is a supersequence of A.   \n(e) Describe an algorithm to find a path in $G$ whose label has minimum edit distance from A. \n15. A polygonal path is a sequence of line segments joined end-to-end; the endpoints of these line segments are called the vertices of the path. The length of a polygonal path is the sum of the lengths of its segments. A polygonal path with vertices $( x _ { 1 } , y _ { 1 } ) , ( x _ { 2 } , y _ { 2 } ) , ldots , ( x _ { k } , y _ { k } )$ is monotonically increasing if $x _ { i } < x _ { i + 1 }$ and $y _ { i } < y _ { i + 1 }$ for every index $i$ —informally, each vertex of the path is above and to the right of its predecessor. \nSuppose you are given a set $s$ of $n$ points in the plane, represented as two arrays $X [ 1 ldots n ]$ and $Y [ 1 ldots n ]$ . Describe and analyze an algorithm to compute the length of the longest monotonically increasing path with vertices in $s$ . Assume you have a subroutine $mathrm { L E N G T H } ( x , y , x ^ { prime } , y ^ { prime } )$ that returns the length of the segment from $( x , y )$ to $( x ^ { prime } , y ^ { prime } )$ . \n16. For any two nodes $u$ and $w$ in a directed acyclic graph $G$ , the interval $G [ u , w ]$ is the union of all directed paths in $G$ from $u$ to $nu$ . Equivalently, $G [ u , w ]$ consists of all vertices $nu$ such that $nu in r e a c h ( u )$ and $w in r e a c h ( x )$ , together with all the edges in $G$ connecting those vertices. \nSuppose we are given a directed acyclic graph $G$ , in which every vertex has a numerical weight, which may be positive, negative, or zero. \n(a) Describe an efficient algorithm to find the maximum-weight interval in $G$ , where the weight of each interval is the sum of the weights of its vertices.   \n(b) Describe an efficient algorithm to find the largest vertex weight in every interval in $G$ . Your algorithm should compute a two-dimensional array $M a x W t [ 1 ldots V , 1 ldots V ]$ where each entry $M a x W t [ u , w ]$ is the maximum weight among all vertices in the interval $G [ u , w ]$ . In particular, if $G [ u , w ]$ is empty, then $M a x W t [ u , w ]$ should be $- infty$ . \n17. Let $G$ be a directed acyclic graph whose vertices have labels from some fixed alphabet. Any directed path in $G$ has a label, which is a string obtained by concatenating the labels of its vertices. Recall that a palindrome is a string that is equal to its reversal. \n(a) Describe and analyze an algorithm to find the length of the longest palindrome that is the label of a path in $G$ . For example, given the graph in Figure 6.23, your algorithm should return the integer 6, which is the length of the palindrome HANNAH. \n(b) Describe an algorithm to find the longest palindrome that is a subsequence of the label of a path in $G$ .   \n(c) Suppose $G$ has a single source s and a single sink t. Describe an algorithm to find the shortest palindrome that is a supersequence of the label of a path in $G$ from $s$ to $t$ . \n18. Suppose you are given two directed acyclic graphs $G$ and $H$ in which every node has a label from some finite alphabet; different nodes may have the same label. The label of a path in either dag is the string obtained by concatenating the labels of its vertices. \n(a) Describe and analyze an algorithm to compute the length of the longest string that is both the label of a path in $G$ and the label of a path in $H$ .   \n(b) Describe and analyze an algorithm to compute the length of the longest string that is both a subsequence of the label of a path in $G$ and a subsequence of the label of a path in $H$ .   \n(c) Describe and analyze an algorithm to compute the length of the shortest string that is both a supersequence of the label of a path in $G$ and a supersequence of the label of a path in $H$ . [Hint: This is easier than it looks.] \n19. Let $G$ be an arbitrary (not necessarily acyclic) directed graph in which every vertex $nu$ has an integer weight $w ( nu )$ . \n(a) Describe an algorithm to find the longest directed path in $G$ whose vertex weights define an increasing sequence.   \n(b) Describe and analyze an algorithm to determine the maximum-weight vertex reachable from each vertex in $G$ . That is, for each vertex $nu$ , your algorithm needs to compute maxreach $( nu ) : = operatorname* { m a x } { w ( x ) mid x in r e a c h ( nu ) }$ . \n20. (a) Suppose you are given a directed acyclic graph $G$ with $n$ vertices and an integer $k leq n$ . Describe an efficient algorithm to find a set of at most $k$ vertex-disjoint paths that visit every vertex in $G$ . (b) Now suppose the edges of the input dag $G$ have weights, which may be positive, negative, or zero. Describe an efficient algorithm to find a set of at most $k$ vertex-disjoint paths with minimum total weight that visit every vertex in $G$ . \nYour algorithms should run in $O ( n ^ { k + c } )$ time for some small constant c. A single vertex is a path with weight zero. (We will see a more efficient algorithm for part (a) in Chapter 11.) \n21. Kris is a professional rock climber who is competing in the U.S. climbing nationals. The competition requires Kris to use as many holds on the climbing wall as possible, using only transitions that have been explicitly allowed by the route-setter. \nThe climbing wall has $n$ holds. Kris is given a list of $m$ pairs $( x , y )$ of holds, each indicating that moving directly from hold $x$ to hold $y$ is allowed; however, moving directly from $y$ to $x$ is not allowed unless the list also includes the pair $( y , x )$ . Kris needs to figure out a sequence of allowed transitions that uses as many holds as possible, since each new hold increases his score by one point. The rules allow Kris to choose the first and last hold in his climbing route. The rules also allow him to use each hold as many times as he likes; however, only the first use of each hold increases Kris’s score. \n(a) Define the natural graph representing the input. Describe and analyze an algorithm to solve Kris’s climbing problem if you are guaranteed that the input graph is a dag.   \n(b) Describe and analyze an algorithm to solve Kris’s climbing problem with no restrictions on the input graph. \nBoth of your algorithms should output the maximum possible score that Kris can earn. \n22. There are $n$ galaxies connected by $m$ intergalactic teleport-ways. Each teleport-way joins two galaxies and can be traversed in both directions. However, the company that runs the teleport-ways has established an extremely lucrative cost structure: Anyone can teleport further from their home galaxy at no cost whatsoever, but teleporting toward their home galaxy is prohibitively expensive. \nJudy has decided to take a sabbatical tour of the universe by visiting as many galaxies as possible, starting at her home galaxy. To save on travel expenses, she wants to teleport away from her home galaxy at every step, except for the very last teleport home. \n(a) Describe and analyze an algorithm to compute the maximum number of galaxies that Judy can visit. Your input consists of an undirected graph $G$ with $n$ vertices and $m$ edges describing the teleport-way network, an integer $1 leq s leq n$ identifying Judy’s home galaxy, and an array $D [ 1 ldots n ]$ containing the distances of each galaxy from s.   \nn(b) Just before embarking on her universal tour, Judy wins the space lottery, giving her just enough money to afford two teleports toward her home galaxy. Describe a new algorithm to compute the maximum number of distinct galaxies Judy can visit. She can visit the same galaxy more than once, but crucially, only the first visit counts toward her total. \n23. The Doctor and River Song decide to play a game on a directed acyclic graph $G$ , which has one source $s$ and one sink $t$ .8 \nEach player has a token on one of the vertices of $G$ . At the start of the game, The Doctor’s token is on the source vertex s, and River’s token is on the sink vertex t. The players alternate turns, with The Doctor moving first. On each of his turns, the Doctor moves his token forward along a directed edge; on each of her turns, River moves her token backward along a directed edge. \nIf the two tokens ever meet on the same vertex, River wins the game. (“Hello, Sweetie!”) If the Doctor’s token reaches t or River’s token reaches s before the two tokens meet, then the Doctor wins the game. \nDescribe and analyze an algorithm to determine who wins this game, assuming both players play perfectly. That is, if the Doctor can win no matter how River moves, then your algorithm should output “Doctor”, and if River can win no matter how the Doctor moves, your algorithm should output “River”. (Why are these the only two possibilities?) The input to your algorithm is the graph $G$ . \n$a v _ { 2 4 }$ . Let $x = x _ { 1 } x _ { 2 } ldots x _ { n }$ be a given $n$ -character string over some finite alphabet $Sigma$ , and let $A$ be a deterministic finite-state machine with m states over the same alphabet. \n(a) Describe and analyze an algorithm to compute the length of the longest subsequence of $x$ that is accepted by $A .$ . For example, if A accepts the language $( mathsf { A R } ) ^ { * }$ and $x =$ ABRACADABRA, your algorithm should output the number 4, which is the length of the subsequence ARAR.   \n(b) Describe and analyze an algorithm to compute the length of the shortest supersequence of $x$ that is accepted by $A$ . For example, if $A$ accepts the language (ABCDR)∗ and $x =$ ABRACADABRA, your algorithm should output the number 25, which is the length of the supersequence ABCDRABCDRABCDRABCDRABCDR. \nAnalyze your algorithms in terms of the length $n$ of the input string, the number m of states in the finite-state machine, and the size of the alphabet $Sigma$ . \n25. Not every dynamic programming algorithm can be modeled as finding an optimal path through a directed acyclic graph, but every dynamic programming algorithm does process some underlying dependency graph in postorder. \n(a) Suppose we are given a directed acyclic graph $G$ where every node stores a numerical search key. Describe and analyze an algorithm to find the largest binary search tree that is a subgraph of $G$ .   \n(b) Suppose we are given a directed acyclic graph $G$ and two vertices $s$ and $t$ . Describe an algorithm to compute the number of directed paths in $G$ from s to $t$ . (Assume that any arithmetic operation requires $O ( 1 )$ time.) \n(c) Let $G$ be a directed acyclic graph with the following features: \n• $G$ has a single source $s$ and several sinks $t _ { 1 } , t _ { 2 } , ldots , t _ { k }$ . • Each edge $nu {  } w$ has an associated weight $p ( nu {  } w )$ between 0 and 1. • For each non\u0001-sink vertex $nu$ , the total weight \u0001of all edges leaving $nu$ is 1; that is, $begin{array} { r } { sum _ { w } p ( nu to w ) = 1 } end{array}$ . \nThe weights $p ( nu {  } w )$ defi\u0001ne a random walk in $G$ from the source $s$ to some sink $t _ { i }$ ; after reac\u0001hing any non-sink vertex $nu$ , the walk follows edge $nu {  } w$ with probability $p ( nu {  } w )$ . All probabilities are mutually independe\u0001nt. Describe and analyze\u0001an algorithm to compute the probability that this random walk reaches sink $t _ { i }$ , for every index i. (Assume that each arithmetic operation takes only $O ( 1 )$ time.) \nWe must all hang together, gentlemen, or else we shall most assuredly hang separately. \n— Benjamin Franklin, at the signing of the Declaration of Independence (July 4, 1776) \nI remember seeking advice from someone—who could it have been?—about whether this work was worth submitting for publication; the reasoning it uses is so very simple....Fortunately he advised me to go ahead, and many years passed before another of my publications became as well-known as this very simple one. \n— Joseph Kruskal, describing his shortest-spanning-subtree algorithm (1997) \nClean ALL the things! \n— Allie Brosh, “This is Why I’ll Never be an Adult”, Hyperbole and a Half, June 17, 2010. \nMinimum Spanning Trees \nSuppose we are given a connected, undirected, weighted graph. This is a graph $G = ( V , E )$ together with a function $boldsymbol { w } colon boldsymbol { E } to mathbb { R }$ that assigns a real weight $w ( e )$ to each edge $e$ , which may be positive, negative, or zero. This chapter describes several algorithms to find the minimum spanning tree of $G$ , that is, the spanning tree $T$ that minimizes the function \nSee Figure 7.1 for an example. \n7.1 Distinct Edge Weights \nAn annoying subtlety in the problem statement is that weighted graphs can have more than one spanning tree with the same minimum weight; in particular, if every edge in $G$ has weight 1, then every spanning tree of $G$ is a minimum spanning tree, with weight $V - 1$ . This ambiguity complicates the development of our algorithms; everything would be much simpler if we could simply assume that minimum spanning trees are unique.",
        "chapter": "Depth-First Search",
        "section": "Exercises",
        "subsection": "N/A",
        "subsubsection": "N/A",
        "textbook_id": 1,
        "node_index": 88
      }
    },
    {
      "node_id": "tb1_node89",
      "content": "We must all hang together, gentlemen, or else we shall most assuredly hang separately. \n— Benjamin Franklin, at the signing of the Declaration of Independence (July 4, 1776) \nI remember seeking advice from someone—who could it have been?—about whether this work was worth submitting for publication; the reasoning it uses is so very simple....Fortunately he advised me to go ahead, and many years passed before another of my publications became as well-known as this very simple one. \n— Joseph Kruskal, describing his shortest-spanning-subtree algorithm (1997) \nClean ALL the things! \n— Allie Brosh, “This is Why I’ll Never be an Adult”, Hyperbole and a Half, June 17, 2010. \nMinimum Spanning Trees \nSuppose we are given a connected, undirected, weighted graph. This is a graph $G = ( V , E )$ together with a function $boldsymbol { w } colon boldsymbol { E } to mathbb { R }$ that assigns a real weight $w ( e )$ to each edge $e$ , which may be positive, negative, or zero. This chapter describes several algorithms to find the minimum spanning tree of $G$ , that is, the spanning tree $T$ that minimizes the function \nSee Figure 7.1 for an example. \n7.1 Distinct Edge Weights \nAn annoying subtlety in the problem statement is that weighted graphs can have more than one spanning tree with the same minimum weight; in particular, if every edge in $G$ has weight 1, then every spanning tree of $G$ is a minimum spanning tree, with weight $V - 1$ . This ambiguity complicates the development of our algorithms; everything would be much simpler if we could simply assume that minimum spanning trees are unique. \n\nFortunately, there is an easy condition that implies the uniqueness we want. \nLemma 7.1. If all edge weights in a connected graph $G$ are distinct, then $G$ has a unique minimum spanning tree. \nProof: Let $G$ be an arbitrary connected graph with two minimum spanning trees $T$ and $T ^ { prime }$ ; we need to prove that some pair of edges in $G$ have the same weight. The proof is essentially a greedy exchange argument. \nEach of our spanning trees must contain an edge that the other tree omits. Let $e$ be a minimum-weight edge in $T setminus T ^ { prime }$ , and let $e ^ { prime }$ be a minimum-weight edge in $T ^ { prime } backslash T$ (breaking ties arbitrarily). Without loss of generality, suppose $w ( e ) leq w ( e ^ { prime } )$ . \nThe subgraph $T ^ { prime } cup { e }$ contains exactly one cycle $C$ , which passes through the edge e. Let $e ^ { prime prime }$ be any edge of this cycle that is not in $T$ . At least one such edge must exist, because $T$ is a tree. (We may or may not have $e ^ { prime prime } = e ^ { prime }$ .) Because $e in T$ , we immediately have $e ^ { prime prime } ne e$ and therefore $e ^ { prime prime } in T ^ { prime } setminus T$ . It follows that $w ( e ^ { prime prime } ) geq w ( e ^ { prime } ) geq w ( e )$ . \nNow consider the spanning tree $T ^ { prime prime } { = } T ^ { prime } { + } e - e ^ { prime prime }$ . (This new tree $T ^ { prime prime }$ might be equal to $T$ .) We immediately have $w ( T ^ { prime prime } ) = w ( T ^ { prime } ) + w ( e ) - w ( e ^ { prime prime } ) leq w ( T ^ { prime } )$ . But $T ^ { prime }$ is a minimum spanning tree, so we must have $w ( T ^ { prime prime } ) = w ( T ^ { prime } )$ ; in other words, $T ^ { prime prime }$ is also a minimum spanning tree. We conclude that $w ( e ) = w ( e ^ { prime prime } )$ , which completes the proof. □ \nIf we already have an algorithm that assumes distinct edge weights, we can still run it on graphs where some edges have equal weights, as long as we have a consistent method for breaking ties. One such method uses the following algorithm in place of simple weight comparisons. ShorterEdge takes as input four integers $i , j , k , l$ , representing four (not necessarily distinct) vertices, and decides which of the two edges $( i , j )$ and $( k , l )$ has “smaller” weight. (Because the input graph undirected, the pairs $( i , j )$ and $( j , i )$ represent the same edge.) \n\nIn light of Lemma 7.1 and this tie-breaking rule, we will safely assume for the rest of this chapter that edge weights are always distinct, and therefore minimum spanning trees are always unique. In particular, we can freely discuss the minimum spanning tree with no confusion. \n7.2 The Only Minimum Spanning Tree Algorithm \nThere are many algorithms to compute minimum spanning trees, but almost all of them are instances of the following generic strategy. The situation is similar to graph traversal, where several different algorithms are all variants of the generic traversal algorithm whatever-first search. \nThe generic minimum spanning tree algorithm maintains an acyclic subgraph $F$ of the input graph $G$ , which we will call the intermediate spanning forest. At all times, $F$ satisfies the following invariant: \n$F$ is a subgraph of the minimum spanning tree of G. \nInitially, $F$ consists of $V$ one-vertex trees. The generic algorithm connects trees in $F$ by adding certain edges between them. When the algorithm halts, $F$ consists of a single spanning tree; our invariant implies that this must be the minimum spanning tree of $G$ . Obviously, we have to be careful about which edges we add to the evolving forest, because not every edge is in the minimum spanning tree. \nAt any stage of its evolution, the intermediate spanning forest $F$ induces two special types of edges in the rest of the graph. \n• An edge is useless if it is not an edge of $F$ , but both its endpoints are in the same component of $F$ .   \n• An edge is safe if it is the minimum-weight edge with exactly one endpoint in some component of $F$ .",
      "metadata": {
        "content": "We must all hang together, gentlemen, or else we shall most assuredly hang separately. \n— Benjamin Franklin, at the signing of the Declaration of Independence (July 4, 1776) \nI remember seeking advice from someone—who could it have been?—about whether this work was worth submitting for publication; the reasoning it uses is so very simple....Fortunately he advised me to go ahead, and many years passed before another of my publications became as well-known as this very simple one. \n— Joseph Kruskal, describing his shortest-spanning-subtree algorithm (1997) \nClean ALL the things! \n— Allie Brosh, “This is Why I’ll Never be an Adult”, Hyperbole and a Half, June 17, 2010. \nMinimum Spanning Trees \nSuppose we are given a connected, undirected, weighted graph. This is a graph $G = ( V , E )$ together with a function $boldsymbol { w } colon boldsymbol { E } to mathbb { R }$ that assigns a real weight $w ( e )$ to each edge $e$ , which may be positive, negative, or zero. This chapter describes several algorithms to find the minimum spanning tree of $G$ , that is, the spanning tree $T$ that minimizes the function \nSee Figure 7.1 for an example. \n7.1 Distinct Edge Weights \nAn annoying subtlety in the problem statement is that weighted graphs can have more than one spanning tree with the same minimum weight; in particular, if every edge in $G$ has weight 1, then every spanning tree of $G$ is a minimum spanning tree, with weight $V - 1$ . This ambiguity complicates the development of our algorithms; everything would be much simpler if we could simply assume that minimum spanning trees are unique. \n\nFortunately, there is an easy condition that implies the uniqueness we want. \nLemma 7.1. If all edge weights in a connected graph $G$ are distinct, then $G$ has a unique minimum spanning tree. \nProof: Let $G$ be an arbitrary connected graph with two minimum spanning trees $T$ and $T ^ { prime }$ ; we need to prove that some pair of edges in $G$ have the same weight. The proof is essentially a greedy exchange argument. \nEach of our spanning trees must contain an edge that the other tree omits. Let $e$ be a minimum-weight edge in $T setminus T ^ { prime }$ , and let $e ^ { prime }$ be a minimum-weight edge in $T ^ { prime } backslash T$ (breaking ties arbitrarily). Without loss of generality, suppose $w ( e ) leq w ( e ^ { prime } )$ . \nThe subgraph $T ^ { prime } cup { e }$ contains exactly one cycle $C$ , which passes through the edge e. Let $e ^ { prime prime }$ be any edge of this cycle that is not in $T$ . At least one such edge must exist, because $T$ is a tree. (We may or may not have $e ^ { prime prime } = e ^ { prime }$ .) Because $e in T$ , we immediately have $e ^ { prime prime } ne e$ and therefore $e ^ { prime prime } in T ^ { prime } setminus T$ . It follows that $w ( e ^ { prime prime } ) geq w ( e ^ { prime } ) geq w ( e )$ . \nNow consider the spanning tree $T ^ { prime prime } { = } T ^ { prime } { + } e - e ^ { prime prime }$ . (This new tree $T ^ { prime prime }$ might be equal to $T$ .) We immediately have $w ( T ^ { prime prime } ) = w ( T ^ { prime } ) + w ( e ) - w ( e ^ { prime prime } ) leq w ( T ^ { prime } )$ . But $T ^ { prime }$ is a minimum spanning tree, so we must have $w ( T ^ { prime prime } ) = w ( T ^ { prime } )$ ; in other words, $T ^ { prime prime }$ is also a minimum spanning tree. We conclude that $w ( e ) = w ( e ^ { prime prime } )$ , which completes the proof. □ \nIf we already have an algorithm that assumes distinct edge weights, we can still run it on graphs where some edges have equal weights, as long as we have a consistent method for breaking ties. One such method uses the following algorithm in place of simple weight comparisons. ShorterEdge takes as input four integers $i , j , k , l$ , representing four (not necessarily distinct) vertices, and decides which of the two edges $( i , j )$ and $( k , l )$ has “smaller” weight. (Because the input graph undirected, the pairs $( i , j )$ and $( j , i )$ represent the same edge.) \n\nIn light of Lemma 7.1 and this tie-breaking rule, we will safely assume for the rest of this chapter that edge weights are always distinct, and therefore minimum spanning trees are always unique. In particular, we can freely discuss the minimum spanning tree with no confusion. \n7.2 The Only Minimum Spanning Tree Algorithm \nThere are many algorithms to compute minimum spanning trees, but almost all of them are instances of the following generic strategy. The situation is similar to graph traversal, where several different algorithms are all variants of the generic traversal algorithm whatever-first search. \nThe generic minimum spanning tree algorithm maintains an acyclic subgraph $F$ of the input graph $G$ , which we will call the intermediate spanning forest. At all times, $F$ satisfies the following invariant: \n$F$ is a subgraph of the minimum spanning tree of G. \nInitially, $F$ consists of $V$ one-vertex trees. The generic algorithm connects trees in $F$ by adding certain edges between them. When the algorithm halts, $F$ consists of a single spanning tree; our invariant implies that this must be the minimum spanning tree of $G$ . Obviously, we have to be careful about which edges we add to the evolving forest, because not every edge is in the minimum spanning tree. \nAt any stage of its evolution, the intermediate spanning forest $F$ induces two special types of edges in the rest of the graph. \n• An edge is useless if it is not an edge of $F$ , but both its endpoints are in the same component of $F$ .   \n• An edge is safe if it is the minimum-weight edge with exactly one endpoint in some component of $F$ .",
        "chapter": "Minimum Spanning Trees",
        "section": "Distinct Edge Weights",
        "subsection": "N/A",
        "subsubsection": "N/A",
        "textbook_id": 1,
        "node_index": 89
      }
    },
    {
      "node_id": "tb1_node90",
      "content": "In light of Lemma 7.1 and this tie-breaking rule, we will safely assume for the rest of this chapter that edge weights are always distinct, and therefore minimum spanning trees are always unique. In particular, we can freely discuss the minimum spanning tree with no confusion. \n7.2 The Only Minimum Spanning Tree Algorithm \nThere are many algorithms to compute minimum spanning trees, but almost all of them are instances of the following generic strategy. The situation is similar to graph traversal, where several different algorithms are all variants of the generic traversal algorithm whatever-first search. \nThe generic minimum spanning tree algorithm maintains an acyclic subgraph $F$ of the input graph $G$ , which we will call the intermediate spanning forest. At all times, $F$ satisfies the following invariant: \n$F$ is a subgraph of the minimum spanning tree of G. \nInitially, $F$ consists of $V$ one-vertex trees. The generic algorithm connects trees in $F$ by adding certain edges between them. When the algorithm halts, $F$ consists of a single spanning tree; our invariant implies that this must be the minimum spanning tree of $G$ . Obviously, we have to be careful about which edges we add to the evolving forest, because not every edge is in the minimum spanning tree. \nAt any stage of its evolution, the intermediate spanning forest $F$ induces two special types of edges in the rest of the graph. \n• An edge is useless if it is not an edge of $F$ , but both its endpoints are in the same component of $F$ .   \n• An edge is safe if it is the minimum-weight edge with exactly one endpoint in some component of $F$ . \nThe same edge could be safe for two different components of $F$ . Some edges of $G setminus F$ are neither safe nor useless; we call these edges undecided. \nAll minimum spanning tree algorithms are based on two simple observations. The first observation was proved by Robert Prim in 1957 (although it is implicit in several earlier algorithms), and the second is immediate. \nLemma 7.2 (Prim). The minimum spanning tree of $G$ contains every safe edge. \nProof: In fact we prove the following stronger statement: For any subset $s$ of the vertices of $G$ , the minimum spanning tree of $G$ contains the minimum-weight edge with exactly one endpoint in S. Like the previous lemma, we prove this claim using a greedy exchange argument. \nLet $s$ be an arbitrary subset of vertices of $G$ , and let $e$ be the lightest edge with exactly one endpoint in $s$ . (Our assumption that all edge weights are distinct implies that e is unique.) Let $T$ be an arbitrary spanning tree that does not contain $e$ ; we need to prove that $T$ is not the minimum spanning tree of $G$ . \nBecause $T$ is connected, it contains a path from one endpoint of $e$ to the other. Because this path starts at a vertex of $s$ and ends at a vertex not in $s$ , it must contain at least one edge with exactly one endpoint in $s$ ; let $e ^ { prime }$ be any such edge. Because $T$ is acyclic, removing $e ^ { prime }$ from $T$ yields a spanning forest with exactly two components, one containing each endpoint of $e$ . Thus, adding $e$ to this forest gives us a new spanning tree $T ^ { prime } = T - e ^ { prime } + e$ . The definition of $e$ implies $w ( e ^ { prime } ) > w ( e )$ , which implies that $T ^ { prime }$ has smaller total weight than $T$ . Thus, $T$ is not the minimum spanning tree of $G$ , which completes the proof. □ \nLemma 7.3. The minimum spanning tree contains no useless edge. \nProof: Adding any useless edge to $F$ would introduce a cycle. \nOur generic minimum spanning tree algorithm repeatedly adds safe edges to the evolving forest $F$ . If $F$ is not yet connected, there must be at least one safe edge, because the input graph $G$ is connected. Thus, no matter which safe edges we add in each iteration, our generic algorithm eventually connects $F$ . By induction, Lemma 7.2 implies that the resulting tree is in fact the minimum spanning tree. Whenever we add new edges to $F$ , some undecided edges may become safe, and other undecided edges may become useless. (Once an edge becomes useless, it stays useless forever.) To fully specify a particular algorithm, we must describe which safe edge(s) to add in each iteration, and how to find those edges. \n\n7.3 Borůvka’s Algorithm \nThe oldest and arguably simplest minimum spanning tree algorithm was discovered by the Czech mathematician Otakar Borůvka in 1926, about a year after Jindřich Saxel asked him how to construct an electrical network connecting several cities using the least amount of wire.2 The algorithm was rediscovered by Gustav Choquet in 1938, rediscovered again by a team of Polish mathematicians led by Józef Łukaszewicz in 1951, and rediscovered again by George Sollin in 1961. Although Sollin never published his rediscovery, it was carefully described and credited in one of the first textbooks on graph algorithms; as a result, this algorithm is sometimes called “Sollin’s algorithm”. \nThe Borůvka / Choquet / Florek-Łukaziewicz-Perkal-Steinhaus-Zubrzycki / Prim / Sollin / Brosh3 algorithm can be summarized in one line: \nHere is Borůvka’s algorithm in more detail. The algorithm calls the CountAndLabel algorithm from Chapter 5 (on page 204) to count the components of $F$ and label each vertex $nu$ with an integer comp $( nu )$ indicating its component.",
      "metadata": {
        "content": "In light of Lemma 7.1 and this tie-breaking rule, we will safely assume for the rest of this chapter that edge weights are always distinct, and therefore minimum spanning trees are always unique. In particular, we can freely discuss the minimum spanning tree with no confusion. \n7.2 The Only Minimum Spanning Tree Algorithm \nThere are many algorithms to compute minimum spanning trees, but almost all of them are instances of the following generic strategy. The situation is similar to graph traversal, where several different algorithms are all variants of the generic traversal algorithm whatever-first search. \nThe generic minimum spanning tree algorithm maintains an acyclic subgraph $F$ of the input graph $G$ , which we will call the intermediate spanning forest. At all times, $F$ satisfies the following invariant: \n$F$ is a subgraph of the minimum spanning tree of G. \nInitially, $F$ consists of $V$ one-vertex trees. The generic algorithm connects trees in $F$ by adding certain edges between them. When the algorithm halts, $F$ consists of a single spanning tree; our invariant implies that this must be the minimum spanning tree of $G$ . Obviously, we have to be careful about which edges we add to the evolving forest, because not every edge is in the minimum spanning tree. \nAt any stage of its evolution, the intermediate spanning forest $F$ induces two special types of edges in the rest of the graph. \n• An edge is useless if it is not an edge of $F$ , but both its endpoints are in the same component of $F$ .   \n• An edge is safe if it is the minimum-weight edge with exactly one endpoint in some component of $F$ . \nThe same edge could be safe for two different components of $F$ . Some edges of $G setminus F$ are neither safe nor useless; we call these edges undecided. \nAll minimum spanning tree algorithms are based on two simple observations. The first observation was proved by Robert Prim in 1957 (although it is implicit in several earlier algorithms), and the second is immediate. \nLemma 7.2 (Prim). The minimum spanning tree of $G$ contains every safe edge. \nProof: In fact we prove the following stronger statement: For any subset $s$ of the vertices of $G$ , the minimum spanning tree of $G$ contains the minimum-weight edge with exactly one endpoint in S. Like the previous lemma, we prove this claim using a greedy exchange argument. \nLet $s$ be an arbitrary subset of vertices of $G$ , and let $e$ be the lightest edge with exactly one endpoint in $s$ . (Our assumption that all edge weights are distinct implies that e is unique.) Let $T$ be an arbitrary spanning tree that does not contain $e$ ; we need to prove that $T$ is not the minimum spanning tree of $G$ . \nBecause $T$ is connected, it contains a path from one endpoint of $e$ to the other. Because this path starts at a vertex of $s$ and ends at a vertex not in $s$ , it must contain at least one edge with exactly one endpoint in $s$ ; let $e ^ { prime }$ be any such edge. Because $T$ is acyclic, removing $e ^ { prime }$ from $T$ yields a spanning forest with exactly two components, one containing each endpoint of $e$ . Thus, adding $e$ to this forest gives us a new spanning tree $T ^ { prime } = T - e ^ { prime } + e$ . The definition of $e$ implies $w ( e ^ { prime } ) > w ( e )$ , which implies that $T ^ { prime }$ has smaller total weight than $T$ . Thus, $T$ is not the minimum spanning tree of $G$ , which completes the proof. □ \nLemma 7.3. The minimum spanning tree contains no useless edge. \nProof: Adding any useless edge to $F$ would introduce a cycle. \nOur generic minimum spanning tree algorithm repeatedly adds safe edges to the evolving forest $F$ . If $F$ is not yet connected, there must be at least one safe edge, because the input graph $G$ is connected. Thus, no matter which safe edges we add in each iteration, our generic algorithm eventually connects $F$ . By induction, Lemma 7.2 implies that the resulting tree is in fact the minimum spanning tree. Whenever we add new edges to $F$ , some undecided edges may become safe, and other undecided edges may become useless. (Once an edge becomes useless, it stays useless forever.) To fully specify a particular algorithm, we must describe which safe edge(s) to add in each iteration, and how to find those edges. \n\n7.3 Borůvka’s Algorithm \nThe oldest and arguably simplest minimum spanning tree algorithm was discovered by the Czech mathematician Otakar Borůvka in 1926, about a year after Jindřich Saxel asked him how to construct an electrical network connecting several cities using the least amount of wire.2 The algorithm was rediscovered by Gustav Choquet in 1938, rediscovered again by a team of Polish mathematicians led by Józef Łukaszewicz in 1951, and rediscovered again by George Sollin in 1961. Although Sollin never published his rediscovery, it was carefully described and credited in one of the first textbooks on graph algorithms; as a result, this algorithm is sometimes called “Sollin’s algorithm”. \nThe Borůvka / Choquet / Florek-Łukaziewicz-Perkal-Steinhaus-Zubrzycki / Prim / Sollin / Brosh3 algorithm can be summarized in one line: \nHere is Borůvka’s algorithm in more detail. The algorithm calls the CountAndLabel algorithm from Chapter 5 (on page 204) to count the components of $F$ and label each vertex $nu$ with an integer comp $( nu )$ indicating its component.",
        "chapter": "Minimum Spanning Trees",
        "section": "The Only Minimum Spanning Tree Algorithm",
        "subsection": "N/A",
        "subsubsection": "N/A",
        "textbook_id": 1,
        "node_index": 90
      }
    },
    {
      "node_id": "tb1_node96",
      "content": "8.1 Shortest Path Trees \nAlmost every algorithm known for computing shortest paths from one vertex to another actually solves (large portions of) the following more general single source shortest path or SSSP problem: Find shortest paths from the source vertex s to every other vertex in the graph. This problem is usually solved by finding a shortest path tree rooted at s that contains all the desired shortest paths. \nIt’s not hard to see that if shortest paths are unique, then they form a tree, because any subpath of a shortest path is itself a shortest path. If there are multiple shortest paths to some vertices, we can always choose one shortest path to each vertex so that the union of the paths is a tree. If there are shortest paths from s to two vertices $u$ and $nu$ that diverge, then meet, then diverge again, we can modify one of the paths without changing its length, so that the two paths only diverge once. \nAlthough they are both optimal spanning trees, shortest-path trees and minimum spanning trees are very different creatures. Shortest-path trees are rooted and directed; minimum spanning trees are unrooted and undirected. Shortest-path trees are most naturally defined for directed graphs; minimum spanning trees are more naturally defined for undirected graphs. If edge weights are distinct, there is only one minimum spanning tree, but every source vertex induces a different shortest-path tree; moreover, it is possible for every shortest path tree to use a different set of edges from the minimum spanning tree. \nn8.2 Negative Edges \nFor most shortest-path problems, where the edge weights correspond to distance or length or time, it is natural to assume that all edge weights are non-negative, or even positive. However, for many applications of shortest-path algorithms, it is natural to consider edges with negative weight. For example, the weight of an edge might represent the cost of moving from one vertex to another, so negative-weight edges represent transitions with negative cost, or equivalently, transitions that earn a profit. \n\nNegative edges are a thorn in the side of most shortest-path problems, because the presence of a negative cycle might imply that shortest paths may not be well-defiend. To be precise, a shortest path from s to $t$ exists if and only if there is at least one path from $s$ to $t$ , but there is no path from $s$ to $t$ that touches a negative cycle. For any path from s to $t$ that touches a negative cycle, there is a shorter path from $s$ to $t$ that goes around the cycle one more time.2 Thus, if at least one path from $s$ to $t$ touches a negative cycle, there is no shortest path from $s$ to $t$ . \nIn part because we need to consider negative edge weights, this chapter explicitly considers only directed graphs. All of the algorithms described here also work for undirected graphs with essentially trivial modifications, if and only if negative edges are prohibited. Correctly handling negative edges in undirected graphs is considerably more subtle. We cannot simply replace every undirected edge with a pair of directed edges, because this would transform any negative edge into a short negative cycle. Subpaths of an undirected shortest path that contains a negative edge are not necessarily shortest paths; consequently, the set of all undirected shortest paths from a single source vertex may not define a tree, even if shortest paths are unique. \nA complete treatment of undirected graphs with negative edges is beyond the scope of this book. I will only mention, for people who want to follow up via Google, that a single shortest path in an undirected graph with negative edges can be computed in $O ( V E + V ^ { 2 } log V )$ time, by a reduction to maximum weighted matching. \n8.3 The Only SSSP Algorithm \nJust like graph traversal and minimum spanning trees, many different SSSP algorithms can be described as special cases of a single generic algorithm, first proposed by Lester Ford in 1956 and independently described by George Dantzig in $1 9 5 7 ^ { 3 }$ and again by George Minty in 1958. Each vertex $nu$ in the graph stores two values, which (inductively) describe a tentative shortest path from $s$ to $nu$ . \n• $operatorname { d i s t } ( nu )$ is the length of the tentative shortest $s {  } nu$ path, or $infty$ if there is no such path.   \n• pred $( nu )$ is the predecessor of $nu$ in the tentative shortest $textstyle { s sim } nu$ path, or Null if there is no such vertex. \nThe predecessor pointers automatically define a tentative shortest-path tree rooted at $s$ ; these pointers are exactly the same as the parent pointers in our generic graph traversal algorithm. At the beginning of the algorithm, we initialize the distances and predecessors as follows: \nDuring the execution of the algorithm, an edge $u {  } nu$ is tense if $mathrm { { } } d i s t ( u ) + w ( u to nu ) <$ $operatorname { d i s t } ( nu )$ . If $u {  } nu$ is tense, the tentative shortest\u0001path $s {  } nu$ is clearly inco\u0001rrect, because the\u0001path $s mathrm { sim } u mathrm {  } nu$ is shorter. We can correct (or at least improve) this obvious overestimate b\u0001y relaxing the edge as follows:",
      "metadata": {
        "content": "8.1 Shortest Path Trees \nAlmost every algorithm known for computing shortest paths from one vertex to another actually solves (large portions of) the following more general single source shortest path or SSSP problem: Find shortest paths from the source vertex s to every other vertex in the graph. This problem is usually solved by finding a shortest path tree rooted at s that contains all the desired shortest paths. \nIt’s not hard to see that if shortest paths are unique, then they form a tree, because any subpath of a shortest path is itself a shortest path. If there are multiple shortest paths to some vertices, we can always choose one shortest path to each vertex so that the union of the paths is a tree. If there are shortest paths from s to two vertices $u$ and $nu$ that diverge, then meet, then diverge again, we can modify one of the paths without changing its length, so that the two paths only diverge once. \nAlthough they are both optimal spanning trees, shortest-path trees and minimum spanning trees are very different creatures. Shortest-path trees are rooted and directed; minimum spanning trees are unrooted and undirected. Shortest-path trees are most naturally defined for directed graphs; minimum spanning trees are more naturally defined for undirected graphs. If edge weights are distinct, there is only one minimum spanning tree, but every source vertex induces a different shortest-path tree; moreover, it is possible for every shortest path tree to use a different set of edges from the minimum spanning tree. \nn8.2 Negative Edges \nFor most shortest-path problems, where the edge weights correspond to distance or length or time, it is natural to assume that all edge weights are non-negative, or even positive. However, for many applications of shortest-path algorithms, it is natural to consider edges with negative weight. For example, the weight of an edge might represent the cost of moving from one vertex to another, so negative-weight edges represent transitions with negative cost, or equivalently, transitions that earn a profit. \n\nNegative edges are a thorn in the side of most shortest-path problems, because the presence of a negative cycle might imply that shortest paths may not be well-defiend. To be precise, a shortest path from s to $t$ exists if and only if there is at least one path from $s$ to $t$ , but there is no path from $s$ to $t$ that touches a negative cycle. For any path from s to $t$ that touches a negative cycle, there is a shorter path from $s$ to $t$ that goes around the cycle one more time.2 Thus, if at least one path from $s$ to $t$ touches a negative cycle, there is no shortest path from $s$ to $t$ . \nIn part because we need to consider negative edge weights, this chapter explicitly considers only directed graphs. All of the algorithms described here also work for undirected graphs with essentially trivial modifications, if and only if negative edges are prohibited. Correctly handling negative edges in undirected graphs is considerably more subtle. We cannot simply replace every undirected edge with a pair of directed edges, because this would transform any negative edge into a short negative cycle. Subpaths of an undirected shortest path that contains a negative edge are not necessarily shortest paths; consequently, the set of all undirected shortest paths from a single source vertex may not define a tree, even if shortest paths are unique. \nA complete treatment of undirected graphs with negative edges is beyond the scope of this book. I will only mention, for people who want to follow up via Google, that a single shortest path in an undirected graph with negative edges can be computed in $O ( V E + V ^ { 2 } log V )$ time, by a reduction to maximum weighted matching. \n8.3 The Only SSSP Algorithm \nJust like graph traversal and minimum spanning trees, many different SSSP algorithms can be described as special cases of a single generic algorithm, first proposed by Lester Ford in 1956 and independently described by George Dantzig in $1 9 5 7 ^ { 3 }$ and again by George Minty in 1958. Each vertex $nu$ in the graph stores two values, which (inductively) describe a tentative shortest path from $s$ to $nu$ . \n• $operatorname { d i s t } ( nu )$ is the length of the tentative shortest $s {  } nu$ path, or $infty$ if there is no such path.   \n• pred $( nu )$ is the predecessor of $nu$ in the tentative shortest $textstyle { s sim } nu$ path, or Null if there is no such vertex. \nThe predecessor pointers automatically define a tentative shortest-path tree rooted at $s$ ; these pointers are exactly the same as the parent pointers in our generic graph traversal algorithm. At the beginning of the algorithm, we initialize the distances and predecessors as follows: \nDuring the execution of the algorithm, an edge $u {  } nu$ is tense if $mathrm { { } } d i s t ( u ) + w ( u to nu ) <$ $operatorname { d i s t } ( nu )$ . If $u {  } nu$ is tense, the tentative shortest\u0001path $s {  } nu$ is clearly inco\u0001rrect, because the\u0001path $s mathrm { sim } u mathrm {  } nu$ is shorter. We can correct (or at least improve) this obvious overestimate b\u0001y relaxing the edge as follows:",
        "chapter": "Shortest Paths",
        "section": "♥Negative Edges",
        "subsection": "N/A",
        "subsubsection": "N/A",
        "textbook_id": 1,
        "node_index": 96
      }
    },
    {
      "node_id": "tb1_node97",
      "content": "A complete treatment of undirected graphs with negative edges is beyond the scope of this book. I will only mention, for people who want to follow up via Google, that a single shortest path in an undirected graph with negative edges can be computed in $O ( V E + V ^ { 2 } log V )$ time, by a reduction to maximum weighted matching. \n8.3 The Only SSSP Algorithm \nJust like graph traversal and minimum spanning trees, many different SSSP algorithms can be described as special cases of a single generic algorithm, first proposed by Lester Ford in 1956 and independently described by George Dantzig in $1 9 5 7 ^ { 3 }$ and again by George Minty in 1958. Each vertex $nu$ in the graph stores two values, which (inductively) describe a tentative shortest path from $s$ to $nu$ . \n• $operatorname { d i s t } ( nu )$ is the length of the tentative shortest $s {  } nu$ path, or $infty$ if there is no such path.   \n• pred $( nu )$ is the predecessor of $nu$ in the tentative shortest $textstyle { s sim } nu$ path, or Null if there is no such vertex. \nThe predecessor pointers automatically define a tentative shortest-path tree rooted at $s$ ; these pointers are exactly the same as the parent pointers in our generic graph traversal algorithm. At the beginning of the algorithm, we initialize the distances and predecessors as follows: \nDuring the execution of the algorithm, an edge $u {  } nu$ is tense if $mathrm { { } } d i s t ( u ) + w ( u to nu ) <$ $operatorname { d i s t } ( nu )$ . If $u {  } nu$ is tense, the tentative shortest\u0001path $s {  } nu$ is clearly inco\u0001rrect, because the\u0001path $s mathrm { sim } u mathrm {  } nu$ is shorter. We can correct (or at least improve) this obvious overestimate b\u0001y relaxing the edge as follows: \nNow that everything is set up, Ford’s generic algorithm has a simple one-line description: \nRepeatedly relax tense edges, until there are no more tense edges. \nFordSSSP(s): InitSSSP(s) while there is at least one tense edge Relax any tense edge \nIf FordSSSP eventually terminates (because there are no more tense edges), then the predecessor pointers correctly define a shortest-path tree, and each value $operatorname { d i s t } ( nu )$ is the actual shortest-path distance from s to $nu$ . In particular, if $s$ cannot reach $nu$ , then $d i s t ( nu ) = infty$ , and if any negative cycle is reachable from $s$ , then the algorithm never terminates. \nThe correctness of Ford’s generic algorithm follows from the following series of simpler claims: \n1. At any moment during the execution of the algorithm, for every vertex $nu$ , the distance $operatorname { d i s t } ( nu )$ is either $infty$ or the length of a walk from $s$ to $nu$ . This claim can be proved by induction on the number of relaxations.   \n2. If the graph has no negative cycles, then $operatorname { d i s t } ( nu )$ is either $infty$ or the length of some simple path from $s$ to $nu$ . Specifically, if $operatorname { d i s t } ( nu )$ is the length of a walk from s to $nu$ that contains a directed cycle, that cycle must have negative length. This claim implies that if $G$ has no negative cycles, the relaxation algorithm eventually halts, because there are only a finite number of simple paths in $G$ .   \n3. If no edge in $G$ is tense, then for every vertex $nu$ , the distance $operatorname { d i s t } ( nu )$ is the length of the predecessor path $s to cdots p r e d ( p r e d ( nu ) ) { to } p r e d ( nu ) { to } nu$ . Specifically, if $nu$ violates this condition bu\u0001t its predecessor p\u0001red $( nu )$ do\u0001es not, the edge pred $( nu ) to nu$ is tense.   \n4. If no edge in $G$ is tens\u0001e, then for every vertex $nu$ , the path of predecessor edges $s to cdots to p r e d ( p r e d ( nu ) ) { to } p r e d ( nu ) { to } nu$ is in fact a shortest path from s to $nu$ . Sp\u0001ecific\u0001ally, if $nu$ violates\u0001this cond\u0001ition but its predecessor $u$ in some shortest path does not, the edge $u {  } nu$ is tense. This claim also implies that if $G$ has a negative cycle, then\u0001 some edge is always tense, so the generic algorithm never halts. \nSo far I haven’t said anything about how to find tense edges, or which tense edge(s) to relax if there is more than one. Just like whatever-first search, there are several different instantiations of Ford’s generic relaxation algorithm. Unlike whatever-first search, however, the efficiency and correctness of each search strategy depends on the structure of the input graph. \n\nThe rest of this chapter considers the four most common instantiations of Ford’s algorithm, each of which is the best choice for a different class of input graphs. I’ll leave the remaining details of the generic correctness proof as exercises, and instead give (more informative, self-contained) correctness proofs for each of these four specific algorithms. \n8.4 Unweighted Graphs: Breadth-First Search \nIn the simplest special case of the shortest path problem, all edges have weight 1, and the length of a path is just the number of edges. This special case can be solved by a species of our generic graph-traversal algorithm called breadth-first search. Breadth-first search is often attributed to Edward Moore, who described it in 1957 (as “Algorithm A”) as the first published method to find the shortest path through a maze.4 Especially in the context of VLSI wiring and robot path planning, breadth-first search is sometimes attributed to Chin Yang Lee, who described several applications of Moore’s “Algorithm A” (with proper credit to Moore) in 1961. However, in 1945, more than a decade before Moore considered mazes, Konrad Zuse described an implementation of breadth-first search, as a method to count and label the components of a disconnected graph.6",
      "metadata": {
        "content": "A complete treatment of undirected graphs with negative edges is beyond the scope of this book. I will only mention, for people who want to follow up via Google, that a single shortest path in an undirected graph with negative edges can be computed in $O ( V E + V ^ { 2 } log V )$ time, by a reduction to maximum weighted matching. \n8.3 The Only SSSP Algorithm \nJust like graph traversal and minimum spanning trees, many different SSSP algorithms can be described as special cases of a single generic algorithm, first proposed by Lester Ford in 1956 and independently described by George Dantzig in $1 9 5 7 ^ { 3 }$ and again by George Minty in 1958. Each vertex $nu$ in the graph stores two values, which (inductively) describe a tentative shortest path from $s$ to $nu$ . \n• $operatorname { d i s t } ( nu )$ is the length of the tentative shortest $s {  } nu$ path, or $infty$ if there is no such path.   \n• pred $( nu )$ is the predecessor of $nu$ in the tentative shortest $textstyle { s sim } nu$ path, or Null if there is no such vertex. \nThe predecessor pointers automatically define a tentative shortest-path tree rooted at $s$ ; these pointers are exactly the same as the parent pointers in our generic graph traversal algorithm. At the beginning of the algorithm, we initialize the distances and predecessors as follows: \nDuring the execution of the algorithm, an edge $u {  } nu$ is tense if $mathrm { { } } d i s t ( u ) + w ( u to nu ) <$ $operatorname { d i s t } ( nu )$ . If $u {  } nu$ is tense, the tentative shortest\u0001path $s {  } nu$ is clearly inco\u0001rrect, because the\u0001path $s mathrm { sim } u mathrm {  } nu$ is shorter. We can correct (or at least improve) this obvious overestimate b\u0001y relaxing the edge as follows: \nNow that everything is set up, Ford’s generic algorithm has a simple one-line description: \nRepeatedly relax tense edges, until there are no more tense edges. \nFordSSSP(s): InitSSSP(s) while there is at least one tense edge Relax any tense edge \nIf FordSSSP eventually terminates (because there are no more tense edges), then the predecessor pointers correctly define a shortest-path tree, and each value $operatorname { d i s t } ( nu )$ is the actual shortest-path distance from s to $nu$ . In particular, if $s$ cannot reach $nu$ , then $d i s t ( nu ) = infty$ , and if any negative cycle is reachable from $s$ , then the algorithm never terminates. \nThe correctness of Ford’s generic algorithm follows from the following series of simpler claims: \n1. At any moment during the execution of the algorithm, for every vertex $nu$ , the distance $operatorname { d i s t } ( nu )$ is either $infty$ or the length of a walk from $s$ to $nu$ . This claim can be proved by induction on the number of relaxations.   \n2. If the graph has no negative cycles, then $operatorname { d i s t } ( nu )$ is either $infty$ or the length of some simple path from $s$ to $nu$ . Specifically, if $operatorname { d i s t } ( nu )$ is the length of a walk from s to $nu$ that contains a directed cycle, that cycle must have negative length. This claim implies that if $G$ has no negative cycles, the relaxation algorithm eventually halts, because there are only a finite number of simple paths in $G$ .   \n3. If no edge in $G$ is tense, then for every vertex $nu$ , the distance $operatorname { d i s t } ( nu )$ is the length of the predecessor path $s to cdots p r e d ( p r e d ( nu ) ) { to } p r e d ( nu ) { to } nu$ . Specifically, if $nu$ violates this condition bu\u0001t its predecessor p\u0001red $( nu )$ do\u0001es not, the edge pred $( nu ) to nu$ is tense.   \n4. If no edge in $G$ is tens\u0001e, then for every vertex $nu$ , the path of predecessor edges $s to cdots to p r e d ( p r e d ( nu ) ) { to } p r e d ( nu ) { to } nu$ is in fact a shortest path from s to $nu$ . Sp\u0001ecific\u0001ally, if $nu$ violates\u0001this cond\u0001ition but its predecessor $u$ in some shortest path does not, the edge $u {  } nu$ is tense. This claim also implies that if $G$ has a negative cycle, then\u0001 some edge is always tense, so the generic algorithm never halts. \nSo far I haven’t said anything about how to find tense edges, or which tense edge(s) to relax if there is more than one. Just like whatever-first search, there are several different instantiations of Ford’s generic relaxation algorithm. Unlike whatever-first search, however, the efficiency and correctness of each search strategy depends on the structure of the input graph. \n\nThe rest of this chapter considers the four most common instantiations of Ford’s algorithm, each of which is the best choice for a different class of input graphs. I’ll leave the remaining details of the generic correctness proof as exercises, and instead give (more informative, self-contained) correctness proofs for each of these four specific algorithms. \n8.4 Unweighted Graphs: Breadth-First Search \nIn the simplest special case of the shortest path problem, all edges have weight 1, and the length of a path is just the number of edges. This special case can be solved by a species of our generic graph-traversal algorithm called breadth-first search. Breadth-first search is often attributed to Edward Moore, who described it in 1957 (as “Algorithm A”) as the first published method to find the shortest path through a maze.4 Especially in the context of VLSI wiring and robot path planning, breadth-first search is sometimes attributed to Chin Yang Lee, who described several applications of Moore’s “Algorithm A” (with proper credit to Moore) in 1961. However, in 1945, more than a decade before Moore considered mazes, Konrad Zuse described an implementation of breadth-first search, as a method to count and label the components of a disconnected graph.6",
        "chapter": "Shortest Paths",
        "section": "The Only SSSP Algorithm",
        "subsection": "N/A",
        "subsubsection": "N/A",
        "textbook_id": 1,
        "node_index": 97
      }
    }
  ],
  "output": {
    "question": "Which of the following statements about graph traversal algorithms is supported by the provided context?",
    "correct_answer": "The strong component graph SCC(G) of any directed graph G is acyclic.",
    "distractors": [
      "Depth-first search can compute the reversal of a directed graph in O(V^2) time.",
      "Minimum spanning trees are always unique regardless of edge weight ties.",
      "Shortest paths in undirected graphs with negative edges can be computed in O(V + E) time."
    ],
    "rationale": "Step 1: Extract relevant information from context snippets. From [1]: 'Prove that for every directed graph G, the strong component graph scc(G) is acyclic.' This directly supports the correct answer. Step 2: Create distractors by modifying or misrepresenting other context elements. From [1]: 'Describe an algorithm to compute the reversal... in O(V + E) time' becomes 'O(V^2) time' for the first distractor. From [3]: 'edge weights are always distinct, and therefore minimum spanning trees are always unique' becomes 'regardless of edge weight ties' for the second distractor. From [5]: 'a single shortest path... can be computed in O(VE + V^2 log V) time' becomes 'O(V + E) time' for the third distractor. Step 3: Formulate the question to test understanding of graph traversal concepts while ensuring the correct answer is explicitly supported by the context."
  },
  "score": {
    "relevance": 1.0,
    "faithfulness": 1.0,
    "integration": 0.0,
    "complexity": 0.0,
    "overall": 0.30000000000000004
  }
}